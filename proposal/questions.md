# Questions 

- How can I generate my own data?
- How can I start a language model locally?

Research proposal questions: 
1. How can we address the challenges posed by variations in hand shapes, positions, and orientations to ensure accurate recognition (beginning and end) and interpretation of image gestures in terms of group and global data sets? 
2.  What methods can be employed to evaluate the effectiveness of the multimodal input interface in enhancing the overall user experience (subjective ratings of user-defined gestures and measuring these for myself and maybe even one or two other individuals (group)?)?  
3. Can I use the ASL data set as a global data set for pre-training of an algorithm that can then be fitted to my data, for instance? 