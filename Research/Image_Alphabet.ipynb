{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into a DataFrame\n",
    "training_data = pd.read_csv('/Users/emilkoch/Desktop/2Tango/archive/sign_mnist_train.csv')\n",
    "\n",
    "#Load the testing data into a DataFrame\n",
    "testing_data = pd.read_csv('/Users/emilkoch/Desktop/2Tango/archive/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_cleaned = training_data.dropna()\n",
    "training_data_cleaned_data_cleaned = training_data.dropna()\n",
    "testing_data_cleaned = testing_data.dropna()\n",
    "testing_data_cleaned = testing_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of        label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0          3     107     118     127     134     139     143     146     150   \n",
      "1          6     155     157     156     156     156     157     156     158   \n",
      "2          2     187     188     188     187     187     186     187     188   \n",
      "3          2     211     211     212     212     211     210     211     210   \n",
      "4         13     164     167     170     172     176     179     180     184   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "27450     13     189     189     190     190     192     193     193     193   \n",
      "27451     23     151     154     157     158     160     161     163     164   \n",
      "27452     18     174     174     174     174     174     175     175     174   \n",
      "27453     17     177     181     184     185     187     189     190     191   \n",
      "27454     23     179     180     180     180     182     181     182     183   \n",
      "\n",
      "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0         153  ...       207       207       207       207       206   \n",
      "1         158  ...        69       149       128        87        94   \n",
      "2         187  ...       202       201       200       199       198   \n",
      "3         210  ...       235       234       233       231       230   \n",
      "4         185  ...        92       105       105       108       133   \n",
      "...       ...  ...       ...       ...       ...       ...       ...   \n",
      "27450     193  ...       132       165        99        77        52   \n",
      "27451     166  ...       198       198       198       198       198   \n",
      "27452     173  ...       121       196       209       208       206   \n",
      "27453     191  ...       119        56        27        58       102   \n",
      "27454     182  ...       108       132       170       194       214   \n",
      "\n",
      "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0           206       206       204       203       202  \n",
      "1           163       175       103       135       149  \n",
      "2           199       198       195       194       195  \n",
      "3           226       225       222       229       163  \n",
      "4           163       157       163       164       179  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "27450       200       234       200       222       225  \n",
      "27451       196       195       195       195       194  \n",
      "27452       204       203       202       200       200  \n",
      "27453        79        47        64        87        93  \n",
      "27454       203       197       205       209       215  \n",
      "\n",
      "[27455 rows x 785 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(training_data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (x) and target variable (y)\n",
    "y_train = training_data_cleaned['label']  # Target variable\n",
    "x_train = training_data_cleaned.drop(columns=['label'])  # Features (drop the 'label' column)\n",
    "x_test = testing_data_cleaned.drop(columns=['label'])  # Features (drop the 'label' column)\n",
    "y_test =  testing_data_cleaned['label']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the feature data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "773/773 [==============================] - 42s 47ms/step - loss: 1.5807 - accuracy: 0.6891 - val_loss: 0.5199 - val_accuracy: 0.9734\n",
      "Epoch 2/10\n",
      "773/773 [==============================] - 38s 49ms/step - loss: 0.6883 - accuracy: 0.9018 - val_loss: 0.4032 - val_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "773/773 [==============================] - 37s 47ms/step - loss: 0.5851 - accuracy: 0.9303 - val_loss: 0.3884 - val_accuracy: 0.9982\n",
      "Epoch 4/10\n",
      "773/773 [==============================] - 38s 49ms/step - loss: 0.5250 - accuracy: 0.9456 - val_loss: 0.3674 - val_accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "773/773 [==============================] - 39s 50ms/step - loss: 0.5158 - accuracy: 0.9492 - val_loss: 0.3666 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "773/773 [==============================] - 39s 51ms/step - loss: 0.4969 - accuracy: 0.9529 - val_loss: 0.3630 - val_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "773/773 [==============================] - 37s 47ms/step - loss: 0.4851 - accuracy: 0.9567 - val_loss: 0.3716 - val_accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "773/773 [==============================] - 37s 48ms/step - loss: 0.4798 - accuracy: 0.9582 - val_loss: 0.3707 - val_accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.4645 - accuracy: 0.9622 - val_loss: 0.3504 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "773/773 [==============================] - 37s 48ms/step - loss: 0.4491 - accuracy: 0.9642 - val_loss: 0.3430 - val_accuracy: 0.9978\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.4882 - accuracy: 0.9438\n",
      "Test Accuracy: 0.9438092708587646\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define the CNN model architecture with regularization and dropout\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # L2 regularization\n",
    "    Dropout(0.5),  # Dropout layer to deactivate 50% of neurons\n",
    "    Dense(26, activation='softmax')  # Output layer with 26 units for 26 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test_scaled.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "773/773 [==============================] - 42s 47ms/step - loss: 1.6262 - accuracy: 0.6686 - val_loss: 0.5379 - val_accuracy: 0.9789\n",
      "Epoch 2/10\n",
      "773/773 [==============================] - 35s 46ms/step - loss: 0.7079 - accuracy: 0.8964 - val_loss: 0.4199 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.5978 - accuracy: 0.9261 - val_loss: 0.3759 - val_accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.5359 - accuracy: 0.9393 - val_loss: 0.3645 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "773/773 [==============================] - 37s 47ms/step - loss: 0.5121 - accuracy: 0.9455 - val_loss: 0.3644 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.4814 - accuracy: 0.9522 - val_loss: 0.3348 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.4718 - accuracy: 0.9548 - val_loss: 0.3265 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "773/773 [==============================] - 36s 47ms/step - loss: 0.4665 - accuracy: 0.9573 - val_loss: 0.3323 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "773/773 [==============================] - 38s 49ms/step - loss: 0.4632 - accuracy: 0.9588 - val_loss: 0.3406 - val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "773/773 [==============================] - 37s 48ms/step - loss: 0.4472 - accuracy: 0.9615 - val_loss: 0.3267 - val_accuracy: 0.9993\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.4487 - accuracy: 0.9564\n",
      "Test Accuracy: 0.9563580751419067\n",
      "225/225 [==============================] - 2s 9ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       331\n",
      "           1       1.00      0.98      0.99       432\n",
      "           2       1.00      1.00      1.00       310\n",
      "           3       0.96      1.00      0.98       245\n",
      "           4       0.97      0.94      0.96       498\n",
      "           5       1.00      1.00      1.00       247\n",
      "           6       0.99      0.99      0.99       348\n",
      "           7       0.95      1.00      0.98       436\n",
      "           8       0.92      0.82      0.87       288\n",
      "          10       1.00      0.89      0.94       331\n",
      "          11       1.00      1.00      1.00       209\n",
      "          12       0.90      0.97      0.93       394\n",
      "          13       1.00      0.73      0.85       291\n",
      "          14       1.00      1.00      1.00       246\n",
      "          15       0.99      1.00      0.99       347\n",
      "          16       0.99      1.00      1.00       164\n",
      "          17       0.77      1.00      0.87       144\n",
      "          18       0.85      1.00      0.92       246\n",
      "          19       0.98      0.78      0.87       248\n",
      "          20       0.97      1.00      0.98       266\n",
      "          21       1.00      0.97      0.98       346\n",
      "          22       1.00      1.00      1.00       206\n",
      "          23       0.90      1.00      0.95       267\n",
      "          24       0.88      0.94      0.91       332\n",
      "\n",
      "    accuracy                           0.96      7172\n",
      "   macro avg       0.96      0.96      0.95      7172\n",
      "weighted avg       0.96      0.96      0.96      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the CNN model architecture with regularization and dropout\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # L2 regularization\n",
    "    Dropout(0.5),  # Dropout layer to deactivate 50% of neurons\n",
    "    Dense(26, activation='softmax')  # Output layer with 26 units for 26 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_scaled.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(x_test_scaled.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Generate predictions for the test data\n",
    "y_pred = model.predict(x_test_scaled.reshape(-1, 28, 28, 1))\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:35:24.791493: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "773/773 [==============================] - 38s 45ms/step - loss: 1.6414 - accuracy: 0.6691 - val_loss: 0.5367 - val_accuracy: 0.9807\n",
      "Epoch 2/10\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 0.6918 - accuracy: 0.9020 - val_loss: 0.4178 - val_accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 0.5967 - accuracy: 0.9248 - val_loss: 0.4008 - val_accuracy: 0.9971\n",
      "Epoch 4/10\n",
      "773/773 [==============================] - 33s 43ms/step - loss: 0.5359 - accuracy: 0.9418 - val_loss: 0.3804 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "773/773 [==============================] - 35s 45ms/step - loss: 0.5145 - accuracy: 0.9477 - val_loss: 0.3772 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "773/773 [==============================] - 35s 45ms/step - loss: 0.5052 - accuracy: 0.9543 - val_loss: 0.3611 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "773/773 [==============================] - 35s 45ms/step - loss: 0.4922 - accuracy: 0.9553 - val_loss: 0.3848 - val_accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "773/773 [==============================] - 34s 43ms/step - loss: 0.4700 - accuracy: 0.9599 - val_loss: 0.3608 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "773/773 [==============================] - 63s 82ms/step - loss: 0.4819 - accuracy: 0.9572 - val_loss: 0.3825 - val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "773/773 [==============================] - 30s 38ms/step - loss: 0.4742 - accuracy: 0.9607 - val_loss: 0.3598 - val_accuracy: 0.9989\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.5136 - accuracy: 0.9576\n",
      "Test Accuracy: 0.957612931728363\n",
      "225/225 [==============================] - 2s 8ms/step\n",
      "Classification Report for the First Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       331\n",
      "           1       1.00      0.99      0.99       432\n",
      "           2       1.00      1.00      1.00       310\n",
      "           3       1.00      1.00      1.00       245\n",
      "           4       0.96      1.00      0.98       498\n",
      "           5       1.00      1.00      1.00       247\n",
      "           6       0.93      0.82      0.87       348\n",
      "           7       0.96      0.95      0.96       436\n",
      "           8       1.00      1.00      1.00       288\n",
      "          10       0.99      1.00      1.00       331\n",
      "          11       1.00      1.00      1.00       209\n",
      "          12       0.93      0.89      0.91       394\n",
      "          13       0.96      0.80      0.87       291\n",
      "          14       1.00      0.98      0.99       246\n",
      "          15       0.98      1.00      0.99       347\n",
      "          16       0.95      1.00      0.98       164\n",
      "          17       0.95      0.85      0.90       144\n",
      "          18       0.87      1.00      0.93       246\n",
      "          19       0.80      0.87      0.83       248\n",
      "          20       0.99      0.99      0.99       266\n",
      "          21       0.94      1.00      0.97       346\n",
      "          22       0.83      1.00      0.91       206\n",
      "          23       0.90      1.00      0.95       267\n",
      "          24       1.00      0.88      0.94       332\n",
      "\n",
      "    accuracy                           0.96      7172\n",
      "   macro avg       0.96      0.96      0.96      7172\n",
      "weighted avg       0.96      0.96      0.96      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the first CNN model architecture with regularization and dropout\n",
    "first_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),  # Dropout layer to deactivate 25% of neurons\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # L2 regularization\n",
    "    Dropout(0.5),  # Dropout layer to deactivate 50% of neurons\n",
    "    Dense(26, activation='softmax')  # Output layer with 26 units for 26 classes\n",
    "])\n",
    "\n",
    "# Compile the first model\n",
    "first_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the first model\n",
    "first_model.fit(x_train_scaled.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "first_model.save('/Users/emilkoch/Desktop/2Tango/messenger/Research/Model_Save/first_model.keras')\n",
    "\n",
    "# Evaluate the first model\n",
    "test_loss, test_accuracy = first_model.evaluate(x_test_scaled.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Generate predictions for the test data using the first model\n",
    "y_pred = first_model.predict(x_test_scaled.reshape(-1, 28, 28, 1))\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print classification report for the first model\n",
    "print(\"Classification Report for the First Model:\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
