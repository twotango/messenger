{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signdata = pd.read_csv('/Users/emilkoch/Library/Mobile Documents/com~apple~CloudDocs/Data Files/signdata.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['List', 'Item', 'EnglishWF(lg10)', 'SignFrequency(M)', 'SignFrequency(SD)', 'SignFrequency(Z)', 'SignFrequency(N)', 'Unknown', 'SignFrequency(M-Native)', 'SignFrequency(SD-Native)', 'SignFreq(Z-native)', 'SignFrequency(N-Native)', 'Unknown(Native)', 'SignFrequency(M-Nonnative)', 'SignFrequency(SD-Nonnative)', 'SignFrequency(N-Nonnative)', 'SignFreq(Z-Nonnative)', 'Unknown(Nonnative)', 'DominantTranslationAgreement', 'DominantTranslationAgreement(Native)', 'DominantTranslationAgreement(Nonnative)', 'Iconicity(M)', 'Iconicity(SD)', 'Iconicity(Z)', 'Iconicity(N)', 'D.Iconicity(M)', 'D.Iconicity(SD)', 'D.Iconicity(N)', 'D.Iconicity(Z)', 'D.Iconicity(M-native)', 'D.Iconicity(SD-native)', 'D.Iconicity(Z-native)', 'D.Iconicity(N-native)', 'GuessConsistency', 'GuessAccuracy', 'Transparency(M)', 'Transparency SD', 'Transparency Z', 'Initialized.2.0', 'FingerspelledLoanSign.2.0', 'Compound.2.0', 'NumberOfMorphemes.2.0', 'SignOnset(ms)', 'SignOffset(ms)', 'SignDuration(ms)', 'ClipDuration(ms)', 'MarkedHandshape.2.0', 'FlexionChange.2.0', 'Spread.2.0', 'SpreadChange.2.0', 'ThumbContact.2.0', 'RepeatedMovement.2.0', 'Contact.2.0', 'UlnarRotation.2.0', 'MarkedHandshapeM2.2.0', 'FlexionChangeM2.2.0', 'SpreadM2.2.0', 'SpreadChangeM2.2.0', 'ThumbContactM2.2.0', 'RepeatedMovementM2.2.0', 'ContactM2.2.0', 'UlnarRotationM2.2.0', 'MarkedHandshapeM3.2.0', 'FlexionChangeM3.2.0', 'SpreadM3.2.0', 'SpreadChangeM3.2.0', 'ThumbContactM3.2.0', 'RepeatedMovementM3.2.0', 'ContactM3.2.0', 'UlnarRotationM3.2.0', 'MarkedHandshapeM4.2.0', 'FlexionChangeM4.2.0', 'SpreadM4.2.0', 'SpreadChangeM4.2.0', 'ThumbContactM4.2.0', 'RepeatedMovementM4.2.0', 'ContactM4.2.0', 'NonDominantHandshapeM4.2.0', 'UlnarRotationM4.2.0', 'MarkedHandshapeM5.2.0', 'FlexionChangeM5.2.0', 'SpreadM5.2.0', 'SpreadChangeM5.2.0', 'ThumbContactM5.2.0', 'SignTypeM5.2.0', 'MovementM5.2.0', 'RepeatedMovementM5.2.0', 'MajorLocationM5.2.0', 'MinorLocationM5.2.0', 'SecondMinorLocationM5.2.0', 'ContactM5.2.0', 'NonDominantHandshapeM5.2.0', 'UlnarRotationM5.2.0', 'MarkedHandshapeM6.2.0', 'FlexionChangeM6.2.0', 'SpreadM6.2.0', 'SpreadChangeM6.2.0', 'ThumbContactM6.2.0', 'SignTypeM6.2.0', 'MovementM6.2.0', 'RepeatedMovementM6.2.0', 'MajorLocationM6.2.0', 'MinorLocationM6.2.0', 'SecondMinorLocationM6.2.0', 'ContactM6.2.0', 'NonDominantHandshapeM6.2.0', 'UlnarRotationM6.2.0', 'SignType.2.0Frequency', 'MajorLocation.2.0Frequency', 'MinorLocation.2.0Frequency', 'SecondMinorLocation.2.0Frequency', 'Movement.2.0Frequency', 'SelectedFingers.2.0Frequency', 'Flexion.2.0Frequency', 'FlexionChange.2.0Frequency', 'RepeatedMovement.2.0Frequency', 'Contact.2.0Frequency', 'Spread.2.0Frequency', 'SpreadChange.2.0Frequency', 'ThumbContact.2.0Frequency', 'ThumbPosition.2.0Frequency', 'UlnarRotation.2.0Frequency', 'Neighborhood Density 2.0', 'Parameter.Neighborhood.Density.2.0', 'PhonotacticProbability', 'Phonological Complexity', 'SignBankReferenceID', 'bglm_aoa', 'empirical_aoa']\n",
      "Categorical Columns: ['EntryID', 'LemmaID', 'Code', 'Batch', 'DominantTranslation', 'NondominantTranslations', 'Iconicity_ID', 'IconicityType', 'LexicalClass', 'Handshape.2.0', 'SelectedFingers.2.0', 'Flexion.2.0', 'ThumbPosition.2.0', 'SignType.2.0', 'Movement.2.0', 'MajorLocation.2.0', 'MinorLocation.2.0', 'SecondMinorLocation.2.0', 'NonDominantHandshape.2.0', 'HandshapeM2.2.0', 'SelectedFingersM2.2.0', 'FlexionM2.2.0', 'ThumbPositionM2.2.0', 'SignTypeM2.2.0', 'MovementM2.2.0', 'MajorLocationM2.2.0', 'MinorLocationM2.2.0', 'SecondMinorLocationM2.2.0', 'NonDominantHandshapeM2.2.0', 'HandshapeM3.2.0', 'SelectedFingersM3.2.0', 'FlexionM3.2.0', 'ThumbPositionM3.2.0', 'SignTypeM3.2.0', 'MovementM3.2.0', 'MajorLocationM3.2.0', 'MinorLocationM3.2.0', 'SecondMinorLocationM3.2.0', 'NonDominantHandshapeM3.2.0', 'HandshapeM4.2.0', 'SelectedFingersM4.2.0', 'FlexionM4.2.0', 'ThumbPositionM4.2.0', 'SignTypeM4.2.0', 'MovementM4.2.0', 'MajorLocationM4.2.0', 'MinorLocationM4.2.0', 'SecondMinorLocationM4.2.0', 'HandshapeM5.2.0', 'SelectedFingersM5.2.0', 'FlexionM5.2.0', 'ThumbPositionM5.2.0', 'HandshapeM6.2.0', 'SelectedFingersM6.2.0', 'FlexionM6.2.0', 'ThumbPositionM6.2.0', 'SignBankAnnotationID', 'SignBankLemmaID', 'SignBankSemanticField', 'InCDI', 'CDISemanticCategory']\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable from features\n",
    "X = signdata.drop(columns=['SignBankEnglishTranslations'])  # Features\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2723\n",
      "129\n",
      "   List  Item  EnglishWF(lg10)  SignFrequency(M)  SignFrequency(SD)  \\\n",
      "0     1     2            3.521             5.143              2.081   \n",
      "1     1     3            4.645             6.032              1.516   \n",
      "2     1     4            2.600             4.429              1.720   \n",
      "3     1     5            2.928             2.621              1.720   \n",
      "4     1     8            3.041             1.579              0.838   \n",
      "\n",
      "   SignFrequency(Z)  SignFrequency(N)  Unknown  SignFrequency(M-Native)  \\\n",
      "0             0.621                21    0.000                    5.167   \n",
      "1             1.068                31    0.000                    6.111   \n",
      "2             0.232                21    0.000                    4.167   \n",
      "3            -0.753                29    0.065                    2.000   \n",
      "4            -1.198                19    0.095                    1.455   \n",
      "\n",
      "   SignFrequency(SD-Native)  ...  ThumbContact.2.0Frequency  \\\n",
      "0                     2.167  ...                      0.684   \n",
      "1                     1.568  ...                      0.684   \n",
      "2                     1.899  ...                      0.684   \n",
      "3                     1.317  ...                      0.316   \n",
      "4                     0.688  ...                      0.684   \n",
      "\n",
      "   ThumbPosition.2.0Frequency  UlnarRotation.2.0Frequency  \\\n",
      "0                       0.657                       0.164   \n",
      "1                       0.657                       0.836   \n",
      "2                       0.657                       0.836   \n",
      "3                       0.343                       0.164   \n",
      "4                       0.343                       0.836   \n",
      "\n",
      "   Neighborhood Density 2.0  Parameter.Neighborhood.Density.2.0  \\\n",
      "0                         4                                 190   \n",
      "1                         5                                 391   \n",
      "2                        11                                 488   \n",
      "3                         0                                 220   \n",
      "4                         1                                 453   \n",
      "\n",
      "   PhonotacticProbability  Phonological Complexity  SignBankReferenceID  \\\n",
      "0                   0.147                      1.0                342.0   \n",
      "1                   0.099                      1.0                199.0   \n",
      "2                   0.821                      2.0               1844.0   \n",
      "3                  -0.505                      2.0               3011.0   \n",
      "4                   0.226                      2.0               2471.0   \n",
      "\n",
      "   bglm_aoa  empirical_aoa  \n",
      "0      22.0           14.0  \n",
      "1      31.0           18.0  \n",
      "2      32.0           28.0  \n",
      "3       NaN            NaN  \n",
      "4       NaN            NaN  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "List                          0\n",
      "Item                          0\n",
      "EnglishWF(lg10)             334\n",
      "SignFrequency(M)              0\n",
      "SignFrequency(SD)             0\n",
      "                           ... \n",
      "PhonotacticProbability        0\n",
      "Phonological Complexity      26\n",
      "SignBankReferenceID         734\n",
      "bglm_aoa                   2190\n",
      "empirical_aoa              2190\n",
      "Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for numerical features\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copy numerical columns\n",
    "X_numerical = X[numerical_cols].copy()\n",
    "print(len(X_numerical))\n",
    "print(len(numerical_cols))\n",
    "print(X_numerical.head())\n",
    "print(X_numerical.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:555: UserWarning: Skipping features without any observed values: ['UlnarRotationM4.2.0' 'FlexionChangeM5.2.0' 'SpreadChangeM5.2.0'\n",
      " 'SignTypeM5.2.0' 'MovementM5.2.0' 'RepeatedMovementM5.2.0'\n",
      " 'MajorLocationM5.2.0' 'MinorLocationM5.2.0' 'SecondMinorLocationM5.2.0'\n",
      " 'ContactM5.2.0' 'NonDominantHandshapeM5.2.0' 'UlnarRotationM5.2.0'\n",
      " 'FlexionChangeM6.2.0' 'SpreadChangeM6.2.0' 'SignTypeM6.2.0'\n",
      " 'MovementM6.2.0' 'RepeatedMovementM6.2.0' 'MajorLocationM6.2.0'\n",
      " 'MinorLocationM6.2.0' 'SecondMinorLocationM6.2.0' 'ContactM6.2.0'\n",
      " 'NonDominantHandshapeM6.2.0' 'UlnarRotationM6.2.0']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values and scaling\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_numerical_imputed = imputer.fit_transform(X_numerical) \n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled  = scaler.fit_transform(X_numerical_imputed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categorical_imputer = SimpleImputer(strategy='most_frequent', add_indicator=False)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Copy categorical columns\n",
    "X_categorical = X[categorical_cols].copy()\n",
    "\n",
    "X_categorical_imputed = categorical_imputer.fit_transform(X_categorical)\n",
    "\n",
    "# Encode categorical features\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(X_categorical))\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "categorical_cols_encoded = encoded_cols.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate numerical and encoded categorical columns\n",
    "X_processed = pd.concat([pd.DataFrame(X_numerical_scaled), encoded_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_processed: (1984, 14110)\n",
      "Shape of y_encoded: (1984,)\n",
      "Number of NaN values in 'SignBankEnglishTranslations' column after dropping: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values from the target variable\n",
    "y_cleaned = signdata['SignBankEnglishTranslations'].dropna()\n",
    "\n",
    "# Index X_processed with the same indices as y_cleaned\n",
    "X_processed_cleaned = X_processed.loc[y_cleaned.index]\n",
    "\n",
    "print(\"Shape of X_processed:\", X_processed_cleaned.shape)\n",
    "print(\"Shape of y_encoded:\", y_cleaned.shape)  # Adjusted to use y_cleaned.shape for consistency\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_encoded = label_encoder.fit_transform(y_cleaned)\n",
    "\n",
    "# Check for NaN values in the target variable after dropping\n",
    "nan_count_after_drop = y_cleaned.isnull().sum()\n",
    "print(\"Number of NaN values in 'SignBankEnglishTranslations' column after dropping:\", nan_count_after_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2723, 1984]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize target encoder with the updated categorical columns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m target_encoder \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mTargetEncoder(cols\u001b[38;5;241m=\u001b[39mcategorical_cols_encoded)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2619\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 455\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2723, 1984]"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize target encoder with the updated categorical columns\n",
    "target_encoder = ce.TargetEncoder(cols=categorical_cols_encoded)\n",
    "\n",
    "# Fit and transform target encoder on the training data\n",
    "X_train_encoded = target_encoder.fit_transform(X_train, y_train)\n",
    "\n",
    "# Transform the testing data using the same target encoding mapping\n",
    "X_test_encoded = target_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27339449541284405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          63       1.00      1.00      1.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "         108       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         160       1.00      1.00      1.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         182       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         225       0.00      0.00      0.00         1\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "         244       0.00      0.00      0.00         1\n",
      "         246       0.00      0.00      0.00         1\n",
      "         259       0.00      0.00      0.00         1\n",
      "         265       0.00      0.00      0.00         1\n",
      "         267       0.00      0.00      0.00         1\n",
      "         279       0.00      0.00      0.00         1\n",
      "         280       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         1\n",
      "         288       0.00      0.00      0.00         1\n",
      "         290       0.00      0.00      0.00         1\n",
      "         292       0.00      0.00      0.00         1\n",
      "         301       0.00      0.00      0.00         1\n",
      "         310       0.00      0.00      0.00         1\n",
      "         312       0.00      0.00      0.00         1\n",
      "         317       0.00      0.00      0.00         1\n",
      "         324       0.00      0.00      0.00         1\n",
      "         326       0.00      0.00      0.00         1\n",
      "         327       0.00      0.00      0.00         1\n",
      "         329       0.00      0.00      0.00         1\n",
      "         332       0.00      0.00      0.00         1\n",
      "         338       0.00      0.00      0.00         1\n",
      "         340       0.00      0.00      0.00         1\n",
      "         344       0.00      0.00      0.00         1\n",
      "         346       0.00      0.00      0.00         1\n",
      "         350       0.00      0.00      0.00         1\n",
      "         352       0.00      0.00      0.00         1\n",
      "         353       0.00      0.00      0.00         1\n",
      "         362       0.00      0.00      0.00         1\n",
      "         363       0.00      0.00      0.00         1\n",
      "         364       0.00      0.00      0.00         1\n",
      "         367       0.00      0.00      0.00         1\n",
      "         380       0.00      0.00      0.00         1\n",
      "         383       0.00      0.00      0.00         1\n",
      "         388       0.00      0.00      0.00         1\n",
      "         390       0.00      0.00      0.00         1\n",
      "         399       0.00      0.00      0.00         1\n",
      "         401       0.00      0.00      0.00         1\n",
      "         414       0.00      0.00      0.00         1\n",
      "         417       0.00      0.00      0.00         1\n",
      "         419       0.00      0.00      0.00         1\n",
      "         421       0.00      0.00      0.00         1\n",
      "         423       0.00      0.00      0.00         1\n",
      "         430       0.00      0.00      0.00         1\n",
      "         438       0.00      0.00      0.00         1\n",
      "         445       0.00      0.00      0.00         1\n",
      "         448       0.00      0.00      0.00         1\n",
      "         449       0.00      0.00      0.00         2\n",
      "         451       0.00      0.00      0.00         1\n",
      "         460       0.00      0.00      0.00         1\n",
      "         461       0.00      0.00      0.00         1\n",
      "         472       0.00      0.00      0.00         1\n",
      "         479       0.00      0.00      0.00         1\n",
      "         480       0.00      0.00      0.00         1\n",
      "         482       0.00      0.00      0.00         1\n",
      "         485       0.00      0.00      0.00         1\n",
      "         491       0.00      0.00      0.00         1\n",
      "         493       0.00      0.00      0.00         1\n",
      "         496       0.00      0.00      0.00         1\n",
      "         501       0.00      0.00      0.00         1\n",
      "         502       0.00      0.00      0.00         1\n",
      "         504       0.00      0.00      0.00         1\n",
      "         515       0.00      0.00      0.00         1\n",
      "         519       0.00      0.00      0.00         1\n",
      "         523       0.00      0.00      0.00         1\n",
      "         528       0.00      0.00      0.00         1\n",
      "         530       0.00      0.00      0.00         1\n",
      "         531       0.00      0.00      0.00         1\n",
      "         533       0.00      0.00      0.00         1\n",
      "         538       0.00      0.00      0.00         1\n",
      "         543       0.00      0.00      0.00         1\n",
      "         544       0.00      0.00      0.00         1\n",
      "         546       0.00      0.00      0.00         1\n",
      "         553       0.00      0.00      0.00         1\n",
      "         565       0.00      0.00      0.00         1\n",
      "         568       0.00      0.00      0.00         1\n",
      "         578       0.00      0.00      0.00         1\n",
      "         586       0.00      0.00      0.00         1\n",
      "         588       0.00      0.00      0.00         1\n",
      "         596       0.00      0.00      0.00         0\n",
      "         597       0.00      0.00      0.00         1\n",
      "         599       0.00      0.00      0.00         1\n",
      "         602       0.00      0.00      0.00         1\n",
      "         617       0.00      0.00      0.00         1\n",
      "         619       0.00      0.00      0.00         1\n",
      "         620       0.00      0.00      0.00         1\n",
      "         625       0.00      0.00      0.00         1\n",
      "         629       0.00      0.00      0.00         1\n",
      "         630       0.00      0.00      0.00         2\n",
      "         631       0.00      0.00      0.00         1\n",
      "         632       0.00      0.00      0.00         1\n",
      "         634       0.00      0.00      0.00         1\n",
      "         638       0.00      0.00      0.00         1\n",
      "         639       0.00      0.00      0.00         1\n",
      "         641       0.00      0.00      0.00         1\n",
      "         645       0.00      0.00      0.00         1\n",
      "         652       0.00      0.00      0.00         1\n",
      "         661       0.00      0.00      0.00         1\n",
      "         665       0.00      0.00      0.00         1\n",
      "         669       0.00      0.00      0.00         1\n",
      "         670       0.00      0.00      0.00         1\n",
      "         676       0.00      0.00      0.00         1\n",
      "         680       0.00      0.00      0.00         1\n",
      "         682       0.00      0.00      0.00         1\n",
      "         684       0.00      0.00      0.00         1\n",
      "         688       0.00      0.00      0.00         1\n",
      "         690       0.00      0.00      0.00         1\n",
      "         695       0.00      0.00      0.00         1\n",
      "         700       0.27      1.00      0.43       147\n",
      "         716       0.00      0.00      0.00         1\n",
      "         720       0.00      0.00      0.00         1\n",
      "         721       0.00      0.00      0.00         1\n",
      "         722       0.00      0.00      0.00         1\n",
      "         725       0.00      0.00      0.00         1\n",
      "         739       0.00      0.00      0.00         1\n",
      "         743       0.00      0.00      0.00         1\n",
      "         747       0.00      0.00      0.00         1\n",
      "         753       0.00      0.00      0.00         1\n",
      "         763       0.00      0.00      0.00         1\n",
      "         764       0.00      0.00      0.00         1\n",
      "         766       0.00      0.00      0.00         1\n",
      "         767       0.00      0.00      0.00         1\n",
      "         768       0.00      0.00      0.00         1\n",
      "         769       0.00      0.00      0.00         1\n",
      "         772       0.00      0.00      0.00         1\n",
      "         774       0.00      0.00      0.00         1\n",
      "         782       0.00      0.00      0.00         1\n",
      "         785       0.00      0.00      0.00         1\n",
      "         787       0.00      0.00      0.00         1\n",
      "         789       0.00      0.00      0.00         1\n",
      "         790       0.00      0.00      0.00         1\n",
      "         791       0.00      0.00      0.00         1\n",
      "         792       0.00      0.00      0.00         1\n",
      "         793       0.00      0.00      0.00         1\n",
      "         795       0.00      0.00      0.00         1\n",
      "         801       0.00      0.00      0.00         1\n",
      "         802       0.00      0.00      0.00         1\n",
      "         804       0.00      0.00      0.00         1\n",
      "         808       0.00      0.00      0.00         1\n",
      "         810       0.00      0.00      0.00         1\n",
      "         812       0.00      0.00      0.00         1\n",
      "         815       0.00      0.00      0.00         1\n",
      "         819       0.00      0.00      0.00         2\n",
      "         821       0.00      0.00      0.00         1\n",
      "         822       0.00      0.00      0.00         1\n",
      "         824       0.00      0.00      0.00         1\n",
      "         832       0.00      0.00      0.00         1\n",
      "         840       0.00      0.00      0.00         1\n",
      "         843       0.00      0.00      0.00         1\n",
      "         845       0.00      0.00      0.00         1\n",
      "         846       0.00      0.00      0.00         1\n",
      "         847       0.00      0.00      0.00         1\n",
      "         851       0.00      0.00      0.00         1\n",
      "         855       0.00      0.00      0.00         1\n",
      "         865       0.00      0.00      0.00         1\n",
      "         887       0.00      0.00      0.00         1\n",
      "         891       0.00      0.00      0.00         1\n",
      "         892       0.00      0.00      0.00         1\n",
      "         899       0.00      0.00      0.00         1\n",
      "         907       0.00      0.00      0.00         1\n",
      "         910       0.00      0.00      0.00         1\n",
      "         911       0.00      0.00      0.00         1\n",
      "         914       0.00      0.00      0.00         1\n",
      "         917       0.00      0.00      0.00         1\n",
      "         923       0.00      0.00      0.00         1\n",
      "         937       0.00      0.00      0.00         1\n",
      "         938       0.00      0.00      0.00         1\n",
      "         942       0.00      0.00      0.00         1\n",
      "         949       0.00      0.00      0.00         1\n",
      "         961       0.00      0.00      0.00         1\n",
      "         962       0.00      0.00      0.00         1\n",
      "         963       0.00      0.00      0.00         1\n",
      "         965       0.00      0.00      0.00         1\n",
      "         972       0.00      0.00      0.00         1\n",
      "         976       0.00      0.00      0.00         0\n",
      "         980       0.00      0.00      0.00         1\n",
      "         982       0.00      0.00      0.00         1\n",
      "         984       0.00      0.00      0.00         1\n",
      "         991       0.00      0.00      0.00         1\n",
      "         996       0.00      0.00      0.00         1\n",
      "        1011       0.00      0.00      0.00         1\n",
      "        1014       0.00      0.00      0.00         1\n",
      "        1016       0.00      0.00      0.00         1\n",
      "        1019       0.00      0.00      0.00         1\n",
      "        1034       0.00      0.00      0.00         1\n",
      "        1043       0.00      0.00      0.00         1\n",
      "        1044       0.00      0.00      0.00         1\n",
      "        1049       0.00      0.00      0.00         1\n",
      "        1055       0.00      0.00      0.00         1\n",
      "        1062       0.00      0.00      0.00         1\n",
      "        1063       0.00      0.00      0.00         1\n",
      "        1067       0.00      0.00      0.00         1\n",
      "        1072       0.00      0.00      0.00         1\n",
      "        1083       0.00      0.00      0.00         1\n",
      "        1087       0.00      0.00      0.00         1\n",
      "        1093       0.00      0.00      0.00         1\n",
      "        1105       0.00      0.00      0.00         1\n",
      "        1108       0.00      0.00      0.00         1\n",
      "        1116       0.00      0.00      0.00         1\n",
      "        1117       0.00      0.00      0.00         1\n",
      "        1130       0.00      0.00      0.00         1\n",
      "        1145       0.00      0.00      0.00         1\n",
      "        1149       0.00      0.00      0.00         1\n",
      "        1156       0.00      0.00      0.00         1\n",
      "        1162       0.00      0.00      0.00         1\n",
      "        1163       0.00      0.00      0.00         1\n",
      "        1165       0.00      0.00      0.00         1\n",
      "        1170       0.00      0.00      0.00         1\n",
      "        1171       0.00      0.00      0.00         1\n",
      "        1173       0.00      0.00      0.00         2\n",
      "        1179       0.00      0.00      0.00         1\n",
      "        1185       0.00      0.00      0.00         1\n",
      "        1186       0.00      0.00      0.00         1\n",
      "        1195       0.00      0.00      0.00         1\n",
      "        1198       0.00      0.00      0.00         1\n",
      "        1201       0.00      0.00      0.00         1\n",
      "        1208       0.00      0.00      0.00         1\n",
      "        1211       0.00      0.00      0.00         1\n",
      "        1221       0.00      0.00      0.00         1\n",
      "        1229       0.00      0.00      0.00         1\n",
      "        1231       0.00      0.00      0.00         1\n",
      "        1247       0.00      0.00      0.00         1\n",
      "        1257       0.00      0.00      0.00         1\n",
      "        1258       0.00      0.00      0.00         1\n",
      "        1261       0.00      0.00      0.00         1\n",
      "        1267       0.00      0.00      0.00         1\n",
      "        1270       0.00      0.00      0.00         1\n",
      "        1277       0.00      0.00      0.00         1\n",
      "        1279       0.00      0.00      0.00         1\n",
      "        1288       0.00      0.00      0.00         1\n",
      "        1291       0.00      0.00      0.00         1\n",
      "        1298       0.00      0.00      0.00         1\n",
      "        1302       0.00      0.00      0.00         1\n",
      "        1303       0.00      0.00      0.00         1\n",
      "        1311       0.00      0.00      0.00         1\n",
      "        1313       0.00      0.00      0.00         1\n",
      "        1323       0.00      0.00      0.00         1\n",
      "        1325       0.00      0.00      0.00         1\n",
      "        1326       0.00      0.00      0.00         1\n",
      "        1330       0.00      0.00      0.00         1\n",
      "        1332       0.00      0.00      0.00         1\n",
      "        1334       0.00      0.00      0.00         1\n",
      "        1342       0.00      0.00      0.00         1\n",
      "        1344       0.00      0.00      0.00         1\n",
      "        1346       0.00      0.00      0.00         1\n",
      "        1349       0.00      0.00      0.00         1\n",
      "        1353       0.00      0.00      0.00         1\n",
      "        1355       0.00      0.00      0.00         1\n",
      "        1358       0.00      0.00      0.00         1\n",
      "        1359       0.00      0.00      0.00         1\n",
      "        1360       0.00      0.00      0.00         1\n",
      "        1364       0.00      0.00      0.00         1\n",
      "        1369       0.00      0.00      0.00         1\n",
      "        1375       0.00      0.00      0.00         1\n",
      "        1397       0.00      0.00      0.00         1\n",
      "        1398       0.00      0.00      0.00         1\n",
      "        1401       0.00      0.00      0.00         1\n",
      "        1402       0.00      0.00      0.00         0\n",
      "        1406       0.00      0.00      0.00         1\n",
      "        1410       0.00      0.00      0.00         1\n",
      "        1411       0.00      0.00      0.00         1\n",
      "        1414       0.00      0.00      0.00         1\n",
      "        1426       0.00      0.00      0.00         1\n",
      "        1434       0.00      0.00      0.00         1\n",
      "        1436       0.00      0.00      0.00         1\n",
      "        1438       0.00      0.00      0.00         1\n",
      "        1440       0.00      0.00      0.00         1\n",
      "        1441       0.00      0.00      0.00         0\n",
      "        1444       0.00      0.00      0.00         1\n",
      "        1446       0.00      0.00      0.00         1\n",
      "        1448       0.00      0.00      0.00         1\n",
      "        1453       0.00      0.00      0.00         1\n",
      "        1455       0.00      0.00      0.00         1\n",
      "        1463       0.00      0.00      0.00         1\n",
      "        1470       0.00      0.00      0.00         1\n",
      "        1471       0.00      0.00      0.00         1\n",
      "        1472       0.00      0.00      0.00         1\n",
      "        1476       0.00      0.00      0.00         1\n",
      "        1482       0.00      0.00      0.00         0\n",
      "        1483       0.00      0.00      0.00         1\n",
      "        1488       0.00      0.00      0.00         1\n",
      "        1493       0.00      0.00      0.00         1\n",
      "        1496       0.00      0.00      0.00         2\n",
      "        1497       0.00      0.00      0.00         1\n",
      "        1501       0.00      0.00      0.00         1\n",
      "        1506       0.00      0.00      0.00         1\n",
      "        1515       0.00      0.00      0.00         1\n",
      "        1518       0.00      0.00      0.00         1\n",
      "        1520       0.00      0.00      0.00         1\n",
      "        1521       0.00      0.00      0.00         1\n",
      "        1527       0.00      0.00      0.00         1\n",
      "        1535       0.00      0.00      0.00         1\n",
      "        1536       0.00      0.00      0.00         1\n",
      "        1544       0.00      0.00      0.00         1\n",
      "        1545       0.00      0.00      0.00         1\n",
      "        1550       0.00      0.00      0.00         1\n",
      "        1561       0.00      0.00      0.00         1\n",
      "        1570       0.00      0.00      0.00         1\n",
      "        1580       0.00      0.00      0.00         1\n",
      "        1581       0.00      0.00      0.00         2\n",
      "        1582       0.00      0.00      0.00         1\n",
      "        1589       0.00      0.00      0.00         0\n",
      "        1595       0.00      0.00      0.00         1\n",
      "        1596       0.00      0.00      0.00         1\n",
      "        1598       0.00      0.00      0.00         1\n",
      "        1599       0.00      0.00      0.00         1\n",
      "        1607       0.00      0.00      0.00         1\n",
      "        1610       0.00      0.00      0.00         1\n",
      "        1615       0.00      0.00      0.00         1\n",
      "        1616       0.00      0.00      0.00         1\n",
      "        1622       0.00      0.00      0.00         1\n",
      "        1624       0.00      0.00      0.00         1\n",
      "        1626       0.00      0.00      0.00         1\n",
      "        1627       0.00      0.00      0.00         1\n",
      "        1635       0.00      0.00      0.00         1\n",
      "        1636       0.00      0.00      0.00         1\n",
      "        1637       0.00      0.00      0.00         0\n",
      "        1643       0.00      0.00      0.00         1\n",
      "        1647       0.00      0.00      0.00         1\n",
      "        1656       0.00      0.00      0.00         1\n",
      "        1658       0.00      0.00      0.00         1\n",
      "        1659       0.00      0.00      0.00         1\n",
      "        1661       0.00      0.00      0.00         1\n",
      "        1664       0.00      0.00      0.00         1\n",
      "        1667       0.00      0.00      0.00         1\n",
      "        1671       0.00      0.00      0.00         1\n",
      "        1674       0.00      0.00      0.00         1\n",
      "        1681       0.00      0.00      0.00         1\n",
      "        1682       0.00      0.00      0.00         1\n",
      "        1684       0.00      0.00      0.00         1\n",
      "        1687       0.00      0.00      0.00         1\n",
      "        1692       0.00      0.00      0.00         1\n",
      "        1698       0.00      0.00      0.00         1\n",
      "        1709       0.00      0.00      0.00         1\n",
      "        1712       0.00      0.00      0.00         1\n",
      "        1715       0.00      0.00      0.00         1\n",
      "        1717       0.00      0.00      0.00         1\n",
      "        1718       0.00      0.00      0.00         1\n",
      "        1722       0.00      0.00      0.00         1\n",
      "        1725       0.00      0.00      0.00         1\n",
      "        1726       0.00      0.00      0.00         1\n",
      "        1730       0.00      0.00      0.00         1\n",
      "        1736       0.00      0.00      0.00         1\n",
      "        1738       0.00      0.00      0.00         1\n",
      "        1748       0.00      0.00      0.00         1\n",
      "        1751       0.00      0.00      0.00         1\n",
      "        1760       0.00      0.00      0.00         1\n",
      "        1761       0.00      0.00      0.00         1\n",
      "        1764       0.00      0.00      0.00         1\n",
      "        1765       0.00      0.00      0.00         1\n",
      "        1777       0.00      0.00      0.00         1\n",
      "        1782       0.00      0.00      0.00         1\n",
      "        1787       0.00      0.00      0.00         1\n",
      "        1789       0.00      0.00      0.00         1\n",
      "        1792       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27       545\n",
      "   macro avg       0.01      0.01      0.01       545\n",
      "weighted avg       0.08      0.27      0.12       545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train_encoded.columns = X_train_encoded.columns.astype(str)\n",
    "X_test_encoded.columns = X_test_encoded.columns.astype(str)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_classifier.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importance = xgb_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top features\n",
    "selected_features = feature_importance_df.head(10)['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the classifier on X_processed and y_encoded\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrf_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get feature importances\u001b[39;00m\n\u001b[1;32m     10\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[0;32m--> 440\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m-> 2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2028\u001b[0m     )\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier on X_processed and y_encoded\n",
    "rf_classifier.fit(X_processed, y_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_processed.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select features with importance above threshold\n",
    "threshold = 0.03  # Adjust as needed\n",
    "selected_features_rf = feature_importance_df.loc[feature_importance_df['Importance'] > threshold, 'Feature'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
