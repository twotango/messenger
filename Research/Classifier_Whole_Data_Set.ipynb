{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signdata = pd.read_csv('/Users/emilkoch/Library/Mobile Documents/com~apple~CloudDocs/Data Files/signdata.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['List', 'Item', 'EnglishWF(lg10)', 'SignFrequency(M)', 'SignFrequency(SD)', 'SignFrequency(Z)', 'SignFrequency(N)', 'Unknown', 'SignFrequency(M-Native)', 'SignFrequency(SD-Native)', 'SignFreq(Z-native)', 'SignFrequency(N-Native)', 'Unknown(Native)', 'SignFrequency(M-Nonnative)', 'SignFrequency(SD-Nonnative)', 'SignFrequency(N-Nonnative)', 'SignFreq(Z-Nonnative)', 'Unknown(Nonnative)', 'DominantTranslationAgreement', 'DominantTranslationAgreement(Native)', 'DominantTranslationAgreement(Nonnative)', 'Iconicity(M)', 'Iconicity(SD)', 'Iconicity(Z)', 'Iconicity(N)', 'D.Iconicity(M)', 'D.Iconicity(SD)', 'D.Iconicity(N)', 'D.Iconicity(Z)', 'D.Iconicity(M-native)', 'D.Iconicity(SD-native)', 'D.Iconicity(Z-native)', 'D.Iconicity(N-native)', 'GuessConsistency', 'GuessAccuracy', 'Transparency(M)', 'Transparency SD', 'Transparency Z', 'Initialized.2.0', 'FingerspelledLoanSign.2.0', 'Compound.2.0', 'NumberOfMorphemes.2.0', 'SignOnset(ms)', 'SignOffset(ms)', 'SignDuration(ms)', 'ClipDuration(ms)', 'MarkedHandshape.2.0', 'FlexionChange.2.0', 'Spread.2.0', 'SpreadChange.2.0', 'ThumbContact.2.0', 'RepeatedMovement.2.0', 'Contact.2.0', 'UlnarRotation.2.0', 'MarkedHandshapeM2.2.0', 'FlexionChangeM2.2.0', 'SpreadM2.2.0', 'SpreadChangeM2.2.0', 'ThumbContactM2.2.0', 'RepeatedMovementM2.2.0', 'ContactM2.2.0', 'UlnarRotationM2.2.0', 'MarkedHandshapeM3.2.0', 'FlexionChangeM3.2.0', 'SpreadM3.2.0', 'SpreadChangeM3.2.0', 'ThumbContactM3.2.0', 'RepeatedMovementM3.2.0', 'ContactM3.2.0', 'UlnarRotationM3.2.0', 'MarkedHandshapeM4.2.0', 'FlexionChangeM4.2.0', 'SpreadM4.2.0', 'SpreadChangeM4.2.0', 'ThumbContactM4.2.0', 'RepeatedMovementM4.2.0', 'ContactM4.2.0', 'NonDominantHandshapeM4.2.0', 'UlnarRotationM4.2.0', 'MarkedHandshapeM5.2.0', 'FlexionChangeM5.2.0', 'SpreadM5.2.0', 'SpreadChangeM5.2.0', 'ThumbContactM5.2.0', 'SignTypeM5.2.0', 'MovementM5.2.0', 'RepeatedMovementM5.2.0', 'MajorLocationM5.2.0', 'MinorLocationM5.2.0', 'SecondMinorLocationM5.2.0', 'ContactM5.2.0', 'NonDominantHandshapeM5.2.0', 'UlnarRotationM5.2.0', 'MarkedHandshapeM6.2.0', 'FlexionChangeM6.2.0', 'SpreadM6.2.0', 'SpreadChangeM6.2.0', 'ThumbContactM6.2.0', 'SignTypeM6.2.0', 'MovementM6.2.0', 'RepeatedMovementM6.2.0', 'MajorLocationM6.2.0', 'MinorLocationM6.2.0', 'SecondMinorLocationM6.2.0', 'ContactM6.2.0', 'NonDominantHandshapeM6.2.0', 'UlnarRotationM6.2.0', 'SignType.2.0Frequency', 'MajorLocation.2.0Frequency', 'MinorLocation.2.0Frequency', 'SecondMinorLocation.2.0Frequency', 'Movement.2.0Frequency', 'SelectedFingers.2.0Frequency', 'Flexion.2.0Frequency', 'FlexionChange.2.0Frequency', 'RepeatedMovement.2.0Frequency', 'Contact.2.0Frequency', 'Spread.2.0Frequency', 'SpreadChange.2.0Frequency', 'ThumbContact.2.0Frequency', 'ThumbPosition.2.0Frequency', 'UlnarRotation.2.0Frequency', 'Neighborhood Density 2.0', 'Parameter.Neighborhood.Density.2.0', 'PhonotacticProbability', 'Phonological Complexity', 'SignBankReferenceID', 'bglm_aoa', 'empirical_aoa']\n",
      "Categorical Columns: ['EntryID', 'LemmaID', 'Code', 'Batch', 'DominantTranslation', 'NondominantTranslations', 'Iconicity_ID', 'IconicityType', 'LexicalClass', 'Handshape.2.0', 'SelectedFingers.2.0', 'Flexion.2.0', 'ThumbPosition.2.0', 'SignType.2.0', 'Movement.2.0', 'MajorLocation.2.0', 'MinorLocation.2.0', 'SecondMinorLocation.2.0', 'NonDominantHandshape.2.0', 'HandshapeM2.2.0', 'SelectedFingersM2.2.0', 'FlexionM2.2.0', 'ThumbPositionM2.2.0', 'SignTypeM2.2.0', 'MovementM2.2.0', 'MajorLocationM2.2.0', 'MinorLocationM2.2.0', 'SecondMinorLocationM2.2.0', 'NonDominantHandshapeM2.2.0', 'HandshapeM3.2.0', 'SelectedFingersM3.2.0', 'FlexionM3.2.0', 'ThumbPositionM3.2.0', 'SignTypeM3.2.0', 'MovementM3.2.0', 'MajorLocationM3.2.0', 'MinorLocationM3.2.0', 'SecondMinorLocationM3.2.0', 'NonDominantHandshapeM3.2.0', 'HandshapeM4.2.0', 'SelectedFingersM4.2.0', 'FlexionM4.2.0', 'ThumbPositionM4.2.0', 'SignTypeM4.2.0', 'MovementM4.2.0', 'MajorLocationM4.2.0', 'MinorLocationM4.2.0', 'SecondMinorLocationM4.2.0', 'HandshapeM5.2.0', 'SelectedFingersM5.2.0', 'FlexionM5.2.0', 'ThumbPositionM5.2.0', 'HandshapeM6.2.0', 'SelectedFingersM6.2.0', 'FlexionM6.2.0', 'ThumbPositionM6.2.0', 'SignBankAnnotationID', 'SignBankLemmaID', 'SignBankSemanticField', 'InCDI', 'CDISemanticCategory']\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable from features\n",
    "X = signdata.drop(columns=['SignBankEnglishTranslations'])  # Features\n",
    "y = signdata['SignBankEnglishTranslations']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2723\n",
      "129\n",
      "   List  Item  EnglishWF(lg10)  SignFrequency(M)  SignFrequency(SD)  \\\n",
      "0     1     2            3.521             5.143              2.081   \n",
      "1     1     3            4.645             6.032              1.516   \n",
      "2     1     4            2.600             4.429              1.720   \n",
      "3     1     5            2.928             2.621              1.720   \n",
      "4     1     8            3.041             1.579              0.838   \n",
      "\n",
      "   SignFrequency(Z)  SignFrequency(N)  Unknown  SignFrequency(M-Native)  \\\n",
      "0             0.621                21    0.000                    5.167   \n",
      "1             1.068                31    0.000                    6.111   \n",
      "2             0.232                21    0.000                    4.167   \n",
      "3            -0.753                29    0.065                    2.000   \n",
      "4            -1.198                19    0.095                    1.455   \n",
      "\n",
      "   SignFrequency(SD-Native)  ...  ThumbContact.2.0Frequency  \\\n",
      "0                     2.167  ...                      0.684   \n",
      "1                     1.568  ...                      0.684   \n",
      "2                     1.899  ...                      0.684   \n",
      "3                     1.317  ...                      0.316   \n",
      "4                     0.688  ...                      0.684   \n",
      "\n",
      "   ThumbPosition.2.0Frequency  UlnarRotation.2.0Frequency  \\\n",
      "0                       0.657                       0.164   \n",
      "1                       0.657                       0.836   \n",
      "2                       0.657                       0.836   \n",
      "3                       0.343                       0.164   \n",
      "4                       0.343                       0.836   \n",
      "\n",
      "   Neighborhood Density 2.0  Parameter.Neighborhood.Density.2.0  \\\n",
      "0                         4                                 190   \n",
      "1                         5                                 391   \n",
      "2                        11                                 488   \n",
      "3                         0                                 220   \n",
      "4                         1                                 453   \n",
      "\n",
      "   PhonotacticProbability  Phonological Complexity  SignBankReferenceID  \\\n",
      "0                   0.147                      1.0                342.0   \n",
      "1                   0.099                      1.0                199.0   \n",
      "2                   0.821                      2.0               1844.0   \n",
      "3                  -0.505                      2.0               3011.0   \n",
      "4                   0.226                      2.0               2471.0   \n",
      "\n",
      "   bglm_aoa  empirical_aoa  \n",
      "0      22.0           14.0  \n",
      "1      31.0           18.0  \n",
      "2      32.0           28.0  \n",
      "3       NaN            NaN  \n",
      "4       NaN            NaN  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "List                          0\n",
      "Item                          0\n",
      "EnglishWF(lg10)             334\n",
      "SignFrequency(M)              0\n",
      "SignFrequency(SD)             0\n",
      "                           ... \n",
      "PhonotacticProbability        0\n",
      "Phonological Complexity      26\n",
      "SignBankReferenceID         734\n",
      "bglm_aoa                   2190\n",
      "empirical_aoa              2190\n",
      "Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for numerical features\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copy numerical columns\n",
    "X_numerical = X[numerical_cols].copy()\n",
    "print(len(X_numerical))\n",
    "print(len(numerical_cols))\n",
    "print(X_numerical.head())\n",
    "print(X_numerical.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:555: UserWarning: Skipping features without any observed values: ['UlnarRotationM4.2.0' 'FlexionChangeM5.2.0' 'SpreadChangeM5.2.0'\n",
      " 'SignTypeM5.2.0' 'MovementM5.2.0' 'RepeatedMovementM5.2.0'\n",
      " 'MajorLocationM5.2.0' 'MinorLocationM5.2.0' 'SecondMinorLocationM5.2.0'\n",
      " 'ContactM5.2.0' 'NonDominantHandshapeM5.2.0' 'UlnarRotationM5.2.0'\n",
      " 'FlexionChangeM6.2.0' 'SpreadChangeM6.2.0' 'SignTypeM6.2.0'\n",
      " 'MovementM6.2.0' 'RepeatedMovementM6.2.0' 'MajorLocationM6.2.0'\n",
      " 'MinorLocationM6.2.0' 'SecondMinorLocationM6.2.0' 'ContactM6.2.0'\n",
      " 'NonDominantHandshapeM6.2.0' 'UlnarRotationM6.2.0']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values and scaling\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_numerical_imputed = imputer.fit_transform(X_numerical) \n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled  = scaler.fit_transform(X_numerical_imputed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for categorical features\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Copy categorical columns\n",
    "X_categorical = X[categorical_cols].copy()\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "X_categorical = pd.DataFrame(categorical_imputer.fit_transform(X_categorical), columns=X_categorical.columns)\n",
    "\n",
    "# Encode categorical features\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(X_categorical))\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "categorical_cols_encoded = encoded_cols.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate numerical and encoded categorical columns\n",
    "X_processed = pd.concat([pd.DataFrame(X_numerical_scaled), encoded_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'SignBankEnglishTranslations' column: 739\n",
      "Number of NaN values in 'SignBankEnglishTranslations' column after imputation: 0\n",
      "object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the target variable\n",
    "nan_count = signdata['SignBankEnglishTranslations'].isnull().sum()\n",
    "print(\"Number of NaN values in 'SignBankEnglishTranslations' column:\", nan_count)\n",
    "\n",
    "# Initialize SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply SimpleImputer to fill missing values in the target variable\n",
    "filled_values = imputer.fit_transform(signdata[['SignBankEnglishTranslations']])\n",
    "y_imputed = filled_values.flatten()  # Flatten the 2D array to 1D before assigning back to the Series\n",
    "\n",
    "# Check for NaN values in the target variable after imputation\n",
    "nan_count_after_impute = pd.Series(y_imputed).isnull().sum()\n",
    "print(\"Number of NaN values in 'SignBankEnglishTranslations' column after imputation:\", nan_count_after_impute)\n",
    "print(y_imputed.dtype)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to the target variable 'SignBankEnglishTranslations'\n",
    "y_encoded = label_encoder.fit_transform(y_imputed)\n",
    "print(y_encoded.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Convert feature names to strings\n",
    "X_processed.columns = [str(col) for col in X_processed.columns]\n",
    "\n",
    "# Fit the classifier to your data\n",
    "rf_classifier.fit(X_processed, y_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Filter features based on the threshold\n",
    "selected_features = X_processed.columns[feature_importances > 0.01]\n",
    "print(selected_features.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Correlation with 'SignBankEnglishTranslations':\n",
      "SignBankLemmaID_DOG                   0.201446\n",
      "SignBankAnnotationID_SHOUT            0.196797\n",
      "SignBankSemanticField_Animal          0.158351\n",
      "CDISemanticCategory_Animals           0.119098\n",
      "15                                    0.105201\n",
      "                                        ...   \n",
      "MovementM4.2.0_Straight                    NaN\n",
      "SecondMinorLocationM4.2.0_HandAway         NaN\n",
      "HandshapeM6.2.0_r                          NaN\n",
      "SelectedFingersM6.2.0_im                   NaN\n",
      "FlexionM6.2.0_Crossed                      NaN\n",
      "Length: 14060, dtype: float64\n",
      "Significant Correlations (> 0.01):\n",
      "                           Feature  Correlation\n",
      "0              SignBankLemmaID_DOG     0.201446\n",
      "1       SignBankAnnotationID_SHOUT     0.196797\n",
      "2     SignBankSemanticField_Animal     0.158351\n",
      "3      CDISemanticCategory_Animals     0.119098\n",
      "4                               15     0.105201\n",
      "...                            ...          ...\n",
      "8188    SignBankAnnotationID_SOUTH     0.010002\n",
      "8189         SignBankLemmaID_SOUTH     0.010002\n",
      "8190                 LemmaID_south     0.010002\n",
      "8191     DominantTranslation_south     0.010002\n",
      "8192                 EntryID_south     0.010002\n",
      "\n",
      "[8193 rows x 2 columns]\n",
      "Feature        0\n",
      "Correlation    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate pairwise correlation between 'SignBankEnglishTranslations' and other numerical columns\n",
    "correlation_with_target = X_processed.corrwith(pd.Series(y_encoded))\n",
    "\n",
    "# Sort correlations in descending order\n",
    "correlation_with_target_sorted = correlation_with_target.abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the correlation values\n",
    "print(\"Pairwise Correlation with 'SignBankEnglishTranslations':\")\n",
    "print(correlation_with_target_sorted)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "X_processed_filled = X_processed.fillna(0)\n",
    "\n",
    "# Filter correlations greater than 0.01\n",
    "significant_correlations = correlation_with_target_sorted[correlation_with_target_sorted.abs() > 0.01]\n",
    "\n",
    "# Create a new DataFrame to store significant correlations\n",
    "significant_correlations_df = pd.DataFrame({'Feature': significant_correlations.index, 'Correlation': significant_correlations.values})\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(\"Significant Correlations (> 0.01):\")\n",
    "print(significant_correlations_df)\n",
    "print(significant_correlations_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Features Selected by Random Forest and Significant Correlations (> 0.01):\n",
      "{'SignBankAnnotationID_SHOUT', '103', 'SignBankLemmaID_DOG'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Convert feature names to strings\n",
    "X_processed.columns = [str(col) for col in X_processed.columns]\n",
    "\n",
    "# Fit the classifier to your data\n",
    "rf_classifier.fit(X_processed, y_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Filter features based on the threshold\n",
    "selected_features_rf = X_processed.columns[feature_importances > 0.01]\n",
    "\n",
    "# Convert significant correlations to a set for efficient comparison\n",
    "significant_correlations_set = set(significant_correlations_df['Feature'])\n",
    "\n",
    "# Convert selected features by random forest to a set for efficient comparison\n",
    "selected_features_rf_set = set(selected_features_rf)\n",
    "\n",
    "# Find common features between significant correlations and random forest selected features\n",
    "common_features = significant_correlations_set.intersection(selected_features_rf_set)\n",
    "\n",
    "# Print common features\n",
    "print(\"Common Features Selected by Random Forest and Significant Correlations (> 0.01):\")\n",
    "print(common_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using features with significant correlations: 0.28440366972477066\n",
      "Accuracy using randomly mixed features: 0.3467889908256881\n"
     ]
    }
   ],
   "source": [
    "# Define X_train_corr and X_test_corr using the features from significant_correlations_df\n",
    "X_train_corr = X_train[significant_correlations_df['Feature']]\n",
    "X_test_corr = X_test[significant_correlations_df['Feature']]\n",
    "\n",
    "# Define X_train_rf and X_test_rf using the selected features\n",
    "X_train_rf = X_train[selected_features]\n",
    "X_test_rf = X_test[selected_features]\n",
    "\n",
    "# Train Random Forest using significant correlations\n",
    "rf_corr_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_corr_classifier.fit(X_train_corr, y_train)\n",
    "\n",
    "# Train Random Forest using randomly mixed features\n",
    "rf_rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_rf_classifier.fit(X_train_rf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_corr = rf_corr_classifier.predict(X_test_corr)\n",
    "y_pred_rf = rf_rf_classifier.predict(X_test_rf)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_corr = accuracy_score(y_test, y_pred_corr)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Accuracy using features with significant correlations:\", accuracy_corr)\n",
    "print(\"Accuracy using randomly mixed features:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 4s 33ms/step - loss: 0.0751 - val_loss: 0.0079\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 0.0080 - val_loss: 0.0078\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 2s 28ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 0.0074 - val_loss: 0.0071\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 3s 41ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 2s 30ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 2s 26ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 2s 24ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 2s 25ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "69/69 [==============================] - 0s 4ms/step\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Mean Cosine Similarity: 0.46775527250197635\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your data stored in X_processed and y_encoded\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the autoencoder architecture\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 64  # Adjust as needed\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder_layer = Dense(input_dim, activation='sigmoid')(encoder_layer)\n",
    "\n",
    "autoencoder = Model(input_layer, decoder_layer)\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(input_layer, encoder_layer)\n",
    "X_encoded_train = encoder.predict(X_train)\n",
    "X_encoded_test = encoder.predict(X_test)\n",
    "\n",
    "# Reconstruct data using the trained autoencoder\n",
    "reconstructed_data = autoencoder.predict(X_test)\n",
    "\n",
    "# Combine original test data with reconstructed data\n",
    "X_test_combined = np.concatenate((X_test, reconstructed_data), axis=1)\n",
    "\n",
    "# Compute cosine similarity between original and reconstructed data samples\n",
    "cosine_similarities = cosine_similarity(X_test_combined)\n",
    "\n",
    "# Calculate the mean cosine similarity across all samples\n",
    "mean_cosine_similarity = np.mean(cosine_similarities)\n",
    "print(\"Mean Cosine Similarity:\", mean_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'optimizer': 'rmsprop'}\n",
      "Best Score:  0.4870285264335325\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create the autoencoder model\n",
    "def create_autoencoder(optimizer='adam'):\n",
    "    # Initialize optimizer based on the provided string\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = 'adam'\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop()\n",
    "    elif optimizer == 'adadelta':\n",
    "        optimizer = Adadelta()\n",
    "    elif optimizer == 'adagrad':\n",
    "        optimizer = Adagrad()\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    decoder_layer = Dense(input_dim, activation='sigmoid')(encoder_layer)\n",
    "    autoencoder = Model(input_layer, decoder_layer)\n",
    "    autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return autoencoder\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = KerasRegressor(build_fn=create_autoencoder, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameter grid including additional optimizers\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'rmsprop', 'adadelta', 'adagrad']\n",
    "}\n",
    "\n",
    "# Define a custom scorer for GridSearchCV\n",
    "def mean_cosine_similarity(y_true, y_pred):\n",
    "    cosine_similarities = cosine_similarity(y_true, y_pred)\n",
    "    return np.mean(cosine_similarities)\n",
    "\n",
    "cosine_similarity_scorer = make_scorer(mean_cosine_similarity, greater_is_better=True)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=autoencoder, param_grid=param_grid, scoring=cosine_similarity_scorer, cv=3)\n",
    "grid_result = grid_search.fit(X_train, X_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 7s 64ms/step - loss: 0.5072 - val_loss: 0.2547\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.5030 - val_loss: 0.2524\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4980 - val_loss: 0.2490\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.4900 - val_loss: 0.2433\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 3s 51ms/step - loss: 0.4752 - val_loss: 0.2327\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.4487 - val_loss: 0.2160\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.4072 - val_loss: 0.1911\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.3510 - val_loss: 0.1598\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.2854 - val_loss: 0.1257\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.2194 - val_loss: 0.0942\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.1611 - val_loss: 0.0678\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.1152 - val_loss: 0.0493\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0818 - val_loss: 0.0361\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0586 - val_loss: 0.0272\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0430 - val_loss: 0.0212\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 4s 57ms/step - loss: 0.0326 - val_loss: 0.0173\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0258 - val_loss: 0.0147\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0161 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0121 - val_loss: 0.0095\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0118 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 3s 51ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "69/69 [==============================] - 0s 5ms/step\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Mean Cosine Similarity: 0.3918759372627433\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder architecture with increased complexity, regularization, and batch normalization\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 64  # Adjust as needed\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "# Add a dense layer with ReLU activation and batch normalization\n",
    "encoder_layer1 = Dense(128, activation='relu')(input_layer)\n",
    "encoder_layer1 = BatchNormalization()(encoder_layer1)\n",
    "# Add a dropout layer for regularization\n",
    "encoder_layer1 = Dropout(0.5)(encoder_layer1)\n",
    "\n",
    "# Add another dense layer with ReLU activation and batch normalization\n",
    "encoder_layer2 = Dense(encoding_dim, activation='relu')(encoder_layer1)\n",
    "encoder_layer2 = BatchNormalization()(encoder_layer2)\n",
    "# Add a dropout layer for regularization\n",
    "encoder_layer2 = Dropout(0.5)(encoder_layer2)\n",
    "\n",
    "decoder_layer1 = Dense(128, activation='relu')(encoder_layer2)\n",
    "decoder_layer1 = BatchNormalization()(decoder_layer1)\n",
    "\n",
    "decoder_layer2 = Dense(input_dim, activation='sigmoid')(decoder_layer1)\n",
    "# Add a dropout layer for regularization\n",
    "decoder_layer2 = Dropout(0.5)(decoder_layer2)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_layer, decoder_layer2)\n",
    "\n",
    "# Compile the autoencoder model with RMSprop optimizer\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(input_layer, encoder_layer2)\n",
    "X_encoded_train = encoder.predict(X_train)\n",
    "X_encoded_test = encoder.predict(X_test)\n",
    "\n",
    "# Reconstruct data using the trained autoencoder\n",
    "reconstructed_data = autoencoder.predict(X_test)\n",
    "\n",
    "# Combine original test data with reconstructed data\n",
    "X_test_combined = np.concatenate((X_test, reconstructed_data), axis=1)\n",
    "\n",
    "# Compute cosine similarity between original and reconstructed data samples\n",
    "cosine_similarities = cosine_similarity(X_test_combined)\n",
    "\n",
    "# Calculate the mean cosine similarity across all samples\n",
    "mean_cosine_similarity = np.mean(cosine_similarities)\n",
    "print(\"Mean Cosine Similarity:\", mean_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate schedule: constant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 6s 58ms/step - loss: 0.5071 - val_loss: 0.2547 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.5031 - val_loss: 0.2527 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.4983 - val_loss: 0.2497 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4900 - val_loss: 0.2444 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.4751 - val_loss: 0.2344 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.4478 - val_loss: 0.2171 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.4055 - val_loss: 0.1914 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.3485 - val_loss: 0.1611 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.2823 - val_loss: 0.1281 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.2162 - val_loss: 0.0958 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1583 - val_loss: 0.0705 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.1129 - val_loss: 0.0510 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0801 - val_loss: 0.0373 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0575 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0422 - val_loss: 0.0218 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0320 - val_loss: 0.0178 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0253 - val_loss: 0.0150 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0209 - val_loss: 0.0133 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0179 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.0160 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0146 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0137 - val_loss: 0.0103 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0130 - val_loss: 0.0100 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0124 - val_loss: 0.0098 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0120 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0117 - val_loss: 0.0094 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0115 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0113 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0111 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0109 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0108 - val_loss: 0.0090 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0107 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0106 - val_loss: 0.0089 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0106 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0105 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0104 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.0103 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0103 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0102 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0102 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0102 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0101 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0101 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0101 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0100 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0100 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0100 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0100 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0099 - val_loss: 0.0085 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0099 - val_loss: 0.0085 - lr: 0.0010\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.39306323015021055\n",
      "Training with learning rate schedule: decreasing\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 8s 59ms/step - loss: 0.5070 - val_loss: 0.2546 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.5032 - val_loss: 0.2526 - lr: 9.0484e-04\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 3s 43ms/step - loss: 0.4992 - val_loss: 0.2501 - lr: 8.1873e-04\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.4941 - val_loss: 0.2466 - lr: 7.4082e-04\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.4867 - val_loss: 0.2417 - lr: 6.7032e-04\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4765 - val_loss: 0.2352 - lr: 6.0653e-04\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.4635 - val_loss: 0.2277 - lr: 5.4881e-04\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.4476 - val_loss: 0.2194 - lr: 4.9659e-04\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.4297 - val_loss: 0.2106 - lr: 4.4933e-04\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4105 - val_loss: 0.1997 - lr: 4.0657e-04\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.3908 - val_loss: 0.1892 - lr: 3.6788e-04\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.3710 - val_loss: 0.1798 - lr: 3.3287e-04\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.3518 - val_loss: 0.1707 - lr: 3.0119e-04\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.3337 - val_loss: 0.1615 - lr: 2.7253e-04\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.3168 - val_loss: 0.1531 - lr: 2.4660e-04\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.3009 - val_loss: 0.1462 - lr: 2.2313e-04\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.2866 - val_loss: 0.1390 - lr: 2.0190e-04\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.2735 - val_loss: 0.1331 - lr: 1.8268e-04\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.2619 - val_loss: 0.1277 - lr: 1.6530e-04\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.2513 - val_loss: 0.1226 - lr: 1.4957e-04\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.2417 - val_loss: 0.1182 - lr: 1.3534e-04\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.2333 - val_loss: 0.1140 - lr: 1.2246e-04\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.2257 - val_loss: 0.1105 - lr: 1.1080e-04\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.2190 - val_loss: 0.1073 - lr: 1.0026e-04\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.2129 - val_loss: 0.1044 - lr: 9.0718e-05\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.2074 - val_loss: 0.1019 - lr: 8.2085e-05\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.2026 - val_loss: 0.0995 - lr: 7.4274e-05\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.1982 - val_loss: 0.0976 - lr: 6.7206e-05\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1944 - val_loss: 0.0958 - lr: 6.0810e-05\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1909 - val_loss: 0.0942 - lr: 5.5023e-05\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1878 - val_loss: 0.0927 - lr: 4.9787e-05\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.1850 - val_loss: 0.0914 - lr: 4.5049e-05\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1825 - val_loss: 0.0904 - lr: 4.0762e-05\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1802 - val_loss: 0.0892 - lr: 3.6883e-05\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.1783 - val_loss: 0.0882 - lr: 3.3373e-05\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1765 - val_loss: 0.0875 - lr: 3.0197e-05\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1749 - val_loss: 0.0868 - lr: 2.7324e-05\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1734 - val_loss: 0.0859 - lr: 2.4724e-05\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.1720 - val_loss: 0.0853 - lr: 2.2371e-05\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1708 - val_loss: 0.0849 - lr: 2.0242e-05\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1698 - val_loss: 0.0843 - lr: 1.8316e-05\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.1688 - val_loss: 0.0839 - lr: 1.6573e-05\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1680 - val_loss: 0.0835 - lr: 1.4996e-05\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1672 - val_loss: 0.0832 - lr: 1.3569e-05\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.1664 - val_loss: 0.0828 - lr: 1.2277e-05\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1658 - val_loss: 0.0825 - lr: 1.1109e-05\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1652 - val_loss: 0.0822 - lr: 1.0052e-05\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.1647 - val_loss: 0.0820 - lr: 9.0953e-06\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1643 - val_loss: 0.0818 - lr: 8.2297e-06\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.1639 - val_loss: 0.0817 - lr: 7.4466e-06\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cosine Similarity: 0.910163004335495\n",
      "Training with learning rate schedule: adaptive\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 6s 53ms/step - loss: 0.5073 - val_loss: 0.2548 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.5030 - val_loss: 0.2528 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.4981 - val_loss: 0.2500 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 3s 44ms/step - loss: 0.4899 - val_loss: 0.2446 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4750 - val_loss: 0.2347 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.4481 - val_loss: 0.2176 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.4063 - val_loss: 0.1940 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.3497 - val_loss: 0.1625 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.2838 - val_loss: 0.1298 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.2177 - val_loss: 0.0978 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.1723 - val_loss: 0.0838 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.1462 - val_loss: 0.0717 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.1233 - val_loss: 0.0611 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.1038 - val_loss: 0.0517 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0872 - val_loss: 0.0440 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0734 - val_loss: 0.0378 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 3s 50ms/step - loss: 0.0620 - val_loss: 0.0326 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0528 - val_loss: 0.0283 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.0451 - val_loss: 0.0248 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 4s 51ms/step - loss: 0.0389 - val_loss: 0.0220 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.0339 - val_loss: 0.0197 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0298 - val_loss: 0.0178 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 4s 55ms/step - loss: 0.0265 - val_loss: 0.0163 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 4s 59ms/step - loss: 0.0238 - val_loss: 0.0151 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0217 - val_loss: 0.0141 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 4s 59ms/step - loss: 0.0199 - val_loss: 0.0133 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0185 - val_loss: 0.0126 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 0.0173 - val_loss: 0.0121 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0163 - val_loss: 0.0117 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0155 - val_loss: 0.0113 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 0.0148 - val_loss: 0.0110 - lr: 5.0000e-04\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 0.0143 - val_loss: 0.0107 - lr: 5.0000e-04\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 0.0138 - val_loss: 0.0105 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0134 - val_loss: 0.0103 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 4s 57ms/step - loss: 0.0131 - val_loss: 0.0101 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 4s 53ms/step - loss: 0.0128 - val_loss: 0.0100 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 0.0126 - val_loss: 0.0099 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 4s 64ms/step - loss: 0.0123 - val_loss: 0.0098 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 4s 57ms/step - loss: 0.0121 - val_loss: 0.0097 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 4s 59ms/step - loss: 0.0120 - val_loss: 0.0096 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 4s 54ms/step - loss: 0.0118 - val_loss: 0.0095 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0117 - val_loss: 0.0095 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 0.0116 - val_loss: 0.0094 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0114 - val_loss: 0.0093 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 3s 49ms/step - loss: 0.0113 - val_loss: 0.0093 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 0.0112 - val_loss: 0.0092 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 0.0112 - val_loss: 0.0092 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0111 - val_loss: 0.0092 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 3s 48ms/step - loss: 0.0110 - val_loss: 0.0091 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 0.0110 - val_loss: 0.0091 - lr: 5.0000e-04\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Mean Cosine Similarity: 0.41719396190427765\n",
      "Best learning rate schedule: decreasing\n",
      "Best Mean Cosine Similarity: 0.910163004335495\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rate schedules\n",
    "schedules = {\n",
    "    'constant': lambda epoch: 0.001,\n",
    "    'decreasing': lambda epoch: 0.001 * np.exp(-0.1 * epoch),\n",
    "    'adaptive': lambda epoch: 0.001 if epoch < 10 else 0.0005\n",
    "}\n",
    "\n",
    "# Define a function to train the autoencoder with a given learning rate schedule\n",
    "def train_autoencoder(schedule):\n",
    "    # Define the autoencoder architecture\n",
    "    input_dim = X_train.shape[1]\n",
    "    encoding_dim = 64  # Adjust as needed\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    # Add a dense layer with ReLU activation and batch normalization\n",
    "    encoder_layer1 = Dense(128, activation='relu')(input_layer)\n",
    "    encoder_layer1 = BatchNormalization()(encoder_layer1)\n",
    "    # Add a dropout layer for regularization\n",
    "    encoder_layer1 = Dropout(0.5)(encoder_layer1)\n",
    "\n",
    "    # Add another dense layer with ReLU activation and batch normalization\n",
    "    encoder_layer2 = Dense(encoding_dim, activation='relu')(encoder_layer1)\n",
    "    encoder_layer2 = BatchNormalization()(encoder_layer2)\n",
    "    # Add a dropout layer for regularization\n",
    "    encoder_layer2 = Dropout(0.5)(encoder_layer2)\n",
    "\n",
    "    decoder_layer1 = Dense(128, activation='relu')(encoder_layer2)\n",
    "    decoder_layer1 = BatchNormalization()(decoder_layer1)\n",
    "\n",
    "    decoder_layer2 = Dense(input_dim, activation='sigmoid')(decoder_layer1)\n",
    "    # Add a dropout layer for regularization\n",
    "    decoder_layer2 = Dropout(0.5)(decoder_layer2)\n",
    "\n",
    "    # Create the autoencoder model\n",
    "    autoencoder = Model(input_layer, decoder_layer2)\n",
    "\n",
    "    # Define the optimizer with RMSprop\n",
    "    optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "    # Compile the autoencoder model with RMSprop optimizer\n",
    "    autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Define the learning rate scheduler callback\n",
    "    lr_scheduler = LearningRateScheduler(schedule)\n",
    "\n",
    "    # Train the autoencoder with learning rate scheduler\n",
    "    autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, shuffle=True, validation_data=(X_test, X_test), callbacks=[lr_scheduler])\n",
    "\n",
    "    # Extract features using the encoder part of the autoencoder\n",
    "    encoder = Model(input_layer, encoder_layer2)\n",
    "    X_encoded_test = encoder.predict(X_test)\n",
    "\n",
    "    # Reconstruct data using the trained autoencoder\n",
    "    reconstructed_data = autoencoder.predict(X_test)\n",
    "\n",
    "    # Combine original test data with reconstructed data\n",
    "    X_test_combined = np.concatenate((X_test, reconstructed_data), axis=1)\n",
    "\n",
    "    # Compute cosine similarity between original and reconstructed data samples\n",
    "    cosine_similarities = cosine_similarity(X_test_combined)\n",
    "\n",
    "    # Calculate the mean cosine similarity across all samples\n",
    "    mean_cosine_similarity = np.mean(cosine_similarities)\n",
    "    \n",
    "    return mean_cosine_similarity\n",
    "\n",
    "# Train the autoencoder with different learning rate schedules and keep track of the best one\n",
    "best_schedule = None\n",
    "best_similarity = -1\n",
    "for schedule_name, schedule_func in schedules.items():\n",
    "    print(\"Training with learning rate schedule:\", schedule_name)\n",
    "    similarity = train_autoencoder(schedule_func)\n",
    "    print(\"Mean Cosine Similarity:\", similarity)\n",
    "    if similarity > best_similarity:\n",
    "        best_similarity = similarity\n",
    "        best_schedule = schedule_name\n",
    "\n",
    "print(\"Best learning rate schedule:\", best_schedule)\n",
    "print(\"Best Mean Cosine Similarity:\", best_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
