{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signdata = pd.read_csv('/Users/emilkoch/Library/Mobile Documents/com~apple~CloudDocs/Data Files/signdata.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['List', 'Item', 'EnglishWF(lg10)', 'SignFrequency(M)', 'SignFrequency(SD)', 'SignFrequency(Z)', 'SignFrequency(N)', 'Unknown', 'SignFrequency(M-Native)', 'SignFrequency(SD-Native)', 'SignFreq(Z-native)', 'SignFrequency(N-Native)', 'Unknown(Native)', 'SignFrequency(M-Nonnative)', 'SignFrequency(SD-Nonnative)', 'SignFrequency(N-Nonnative)', 'SignFreq(Z-Nonnative)', 'Unknown(Nonnative)', 'DominantTranslationAgreement', 'DominantTranslationAgreement(Native)', 'DominantTranslationAgreement(Nonnative)', 'Iconicity(M)', 'Iconicity(SD)', 'Iconicity(Z)', 'Iconicity(N)', 'D.Iconicity(M)', 'D.Iconicity(SD)', 'D.Iconicity(N)', 'D.Iconicity(Z)', 'D.Iconicity(M-native)', 'D.Iconicity(SD-native)', 'D.Iconicity(Z-native)', 'D.Iconicity(N-native)', 'GuessConsistency', 'GuessAccuracy', 'Transparency(M)', 'Transparency SD', 'Transparency Z', 'Initialized.2.0', 'FingerspelledLoanSign.2.0', 'Compound.2.0', 'NumberOfMorphemes.2.0', 'SignOnset(ms)', 'SignOffset(ms)', 'SignDuration(ms)', 'ClipDuration(ms)', 'MarkedHandshape.2.0', 'FlexionChange.2.0', 'Spread.2.0', 'SpreadChange.2.0', 'ThumbContact.2.0', 'RepeatedMovement.2.0', 'Contact.2.0', 'UlnarRotation.2.0', 'MarkedHandshapeM2.2.0', 'FlexionChangeM2.2.0', 'SpreadM2.2.0', 'SpreadChangeM2.2.0', 'ThumbContactM2.2.0', 'RepeatedMovementM2.2.0', 'ContactM2.2.0', 'UlnarRotationM2.2.0', 'MarkedHandshapeM3.2.0', 'FlexionChangeM3.2.0', 'SpreadM3.2.0', 'SpreadChangeM3.2.0', 'ThumbContactM3.2.0', 'RepeatedMovementM3.2.0', 'ContactM3.2.0', 'UlnarRotationM3.2.0', 'MarkedHandshapeM4.2.0', 'FlexionChangeM4.2.0', 'SpreadM4.2.0', 'SpreadChangeM4.2.0', 'ThumbContactM4.2.0', 'RepeatedMovementM4.2.0', 'ContactM4.2.0', 'NonDominantHandshapeM4.2.0', 'UlnarRotationM4.2.0', 'MarkedHandshapeM5.2.0', 'FlexionChangeM5.2.0', 'SpreadM5.2.0', 'SpreadChangeM5.2.0', 'ThumbContactM5.2.0', 'SignTypeM5.2.0', 'MovementM5.2.0', 'RepeatedMovementM5.2.0', 'MajorLocationM5.2.0', 'MinorLocationM5.2.0', 'SecondMinorLocationM5.2.0', 'ContactM5.2.0', 'NonDominantHandshapeM5.2.0', 'UlnarRotationM5.2.0', 'MarkedHandshapeM6.2.0', 'FlexionChangeM6.2.0', 'SpreadM6.2.0', 'SpreadChangeM6.2.0', 'ThumbContactM6.2.0', 'SignTypeM6.2.0', 'MovementM6.2.0', 'RepeatedMovementM6.2.0', 'MajorLocationM6.2.0', 'MinorLocationM6.2.0', 'SecondMinorLocationM6.2.0', 'ContactM6.2.0', 'NonDominantHandshapeM6.2.0', 'UlnarRotationM6.2.0', 'SignType.2.0Frequency', 'MajorLocation.2.0Frequency', 'MinorLocation.2.0Frequency', 'SecondMinorLocation.2.0Frequency', 'Movement.2.0Frequency', 'SelectedFingers.2.0Frequency', 'Flexion.2.0Frequency', 'FlexionChange.2.0Frequency', 'RepeatedMovement.2.0Frequency', 'Contact.2.0Frequency', 'Spread.2.0Frequency', 'SpreadChange.2.0Frequency', 'ThumbContact.2.0Frequency', 'ThumbPosition.2.0Frequency', 'UlnarRotation.2.0Frequency', 'Neighborhood Density 2.0', 'Parameter.Neighborhood.Density.2.0', 'PhonotacticProbability', 'Phonological Complexity', 'SignBankReferenceID', 'bglm_aoa', 'empirical_aoa']\n",
      "Categorical Columns: ['EntryID', 'LemmaID', 'Code', 'Batch', 'DominantTranslation', 'NondominantTranslations', 'Iconicity_ID', 'IconicityType', 'LexicalClass', 'Handshape.2.0', 'SelectedFingers.2.0', 'Flexion.2.0', 'ThumbPosition.2.0', 'SignType.2.0', 'Movement.2.0', 'MajorLocation.2.0', 'MinorLocation.2.0', 'SecondMinorLocation.2.0', 'NonDominantHandshape.2.0', 'HandshapeM2.2.0', 'SelectedFingersM2.2.0', 'FlexionM2.2.0', 'ThumbPositionM2.2.0', 'SignTypeM2.2.0', 'MovementM2.2.0', 'MajorLocationM2.2.0', 'MinorLocationM2.2.0', 'SecondMinorLocationM2.2.0', 'NonDominantHandshapeM2.2.0', 'HandshapeM3.2.0', 'SelectedFingersM3.2.0', 'FlexionM3.2.0', 'ThumbPositionM3.2.0', 'SignTypeM3.2.0', 'MovementM3.2.0', 'MajorLocationM3.2.0', 'MinorLocationM3.2.0', 'SecondMinorLocationM3.2.0', 'NonDominantHandshapeM3.2.0', 'HandshapeM4.2.0', 'SelectedFingersM4.2.0', 'FlexionM4.2.0', 'ThumbPositionM4.2.0', 'SignTypeM4.2.0', 'MovementM4.2.0', 'MajorLocationM4.2.0', 'MinorLocationM4.2.0', 'SecondMinorLocationM4.2.0', 'HandshapeM5.2.0', 'SelectedFingersM5.2.0', 'FlexionM5.2.0', 'ThumbPositionM5.2.0', 'HandshapeM6.2.0', 'SelectedFingersM6.2.0', 'FlexionM6.2.0', 'ThumbPositionM6.2.0', 'SignBankAnnotationID', 'SignBankLemmaID', 'SignBankSemanticField', 'InCDI', 'CDISemanticCategory']\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable from features\n",
    "X = signdata.drop(columns=['SignBankEnglishTranslations'])  # Features\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numerical Columns:\", numerical_cols)\n",
    "print(\"Categorical Columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2723\n",
      "129\n",
      "   List  Item  EnglishWF(lg10)  SignFrequency(M)  SignFrequency(SD)  \\\n",
      "0     1     2            3.521             5.143              2.081   \n",
      "1     1     3            4.645             6.032              1.516   \n",
      "2     1     4            2.600             4.429              1.720   \n",
      "3     1     5            2.928             2.621              1.720   \n",
      "4     1     8            3.041             1.579              0.838   \n",
      "\n",
      "   SignFrequency(Z)  SignFrequency(N)  Unknown  SignFrequency(M-Native)  \\\n",
      "0             0.621                21    0.000                    5.167   \n",
      "1             1.068                31    0.000                    6.111   \n",
      "2             0.232                21    0.000                    4.167   \n",
      "3            -0.753                29    0.065                    2.000   \n",
      "4            -1.198                19    0.095                    1.455   \n",
      "\n",
      "   SignFrequency(SD-Native)  ...  ThumbContact.2.0Frequency  \\\n",
      "0                     2.167  ...                      0.684   \n",
      "1                     1.568  ...                      0.684   \n",
      "2                     1.899  ...                      0.684   \n",
      "3                     1.317  ...                      0.316   \n",
      "4                     0.688  ...                      0.684   \n",
      "\n",
      "   ThumbPosition.2.0Frequency  UlnarRotation.2.0Frequency  \\\n",
      "0                       0.657                       0.164   \n",
      "1                       0.657                       0.836   \n",
      "2                       0.657                       0.836   \n",
      "3                       0.343                       0.164   \n",
      "4                       0.343                       0.836   \n",
      "\n",
      "   Neighborhood Density 2.0  Parameter.Neighborhood.Density.2.0  \\\n",
      "0                         4                                 190   \n",
      "1                         5                                 391   \n",
      "2                        11                                 488   \n",
      "3                         0                                 220   \n",
      "4                         1                                 453   \n",
      "\n",
      "   PhonotacticProbability  Phonological Complexity  SignBankReferenceID  \\\n",
      "0                   0.147                      1.0                342.0   \n",
      "1                   0.099                      1.0                199.0   \n",
      "2                   0.821                      2.0               1844.0   \n",
      "3                  -0.505                      2.0               3011.0   \n",
      "4                   0.226                      2.0               2471.0   \n",
      "\n",
      "   bglm_aoa  empirical_aoa  \n",
      "0      22.0           14.0  \n",
      "1      31.0           18.0  \n",
      "2      32.0           28.0  \n",
      "3       NaN            NaN  \n",
      "4       NaN            NaN  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "List                          0\n",
      "Item                          0\n",
      "EnglishWF(lg10)             334\n",
      "SignFrequency(M)              0\n",
      "SignFrequency(SD)             0\n",
      "                           ... \n",
      "PhonotacticProbability        0\n",
      "Phonological Complexity      26\n",
      "SignBankReferenceID         734\n",
      "bglm_aoa                   2190\n",
      "empirical_aoa              2190\n",
      "Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing for numerical features\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copy numerical columns\n",
    "X_numerical = X[numerical_cols].copy()\n",
    "print(len(X_numerical))\n",
    "print(len(numerical_cols))\n",
    "print(X_numerical.head())\n",
    "print(X_numerical.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/impute/_base.py:555: UserWarning: Skipping features without any observed values: ['UlnarRotationM4.2.0' 'FlexionChangeM5.2.0' 'SpreadChangeM5.2.0'\n",
      " 'SignTypeM5.2.0' 'MovementM5.2.0' 'RepeatedMovementM5.2.0'\n",
      " 'MajorLocationM5.2.0' 'MinorLocationM5.2.0' 'SecondMinorLocationM5.2.0'\n",
      " 'ContactM5.2.0' 'NonDominantHandshapeM5.2.0' 'UlnarRotationM5.2.0'\n",
      " 'FlexionChangeM6.2.0' 'SpreadChangeM6.2.0' 'SignTypeM6.2.0'\n",
      " 'MovementM6.2.0' 'RepeatedMovementM6.2.0' 'MajorLocationM6.2.0'\n",
      " 'MinorLocationM6.2.0' 'SecondMinorLocationM6.2.0' 'ContactM6.2.0'\n",
      " 'NonDominantHandshapeM6.2.0' 'UlnarRotationM6.2.0']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values and scaling\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_numerical_imputed = imputer.fit_transform(X_numerical) \n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled  = scaler.fit_transform(X_numerical_imputed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "categorical_imputer = SimpleImputer(strategy='most_frequent', add_indicator=False)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "# Copy categorical columns\n",
    "X_categorical = X[categorical_cols].copy()\n",
    "\n",
    "X_categorical_imputed = categorical_imputer.fit_transform(X_categorical)\n",
    "\n",
    "# Encode categorical features\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(X_categorical))\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "categorical_cols_encoded = encoded_cols.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate numerical and encoded categorical columns\n",
    "X_processed = pd.concat([pd.DataFrame(X_numerical_scaled), encoded_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in 'SignBankEnglishTranslations' column after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fill missing values in the target variable\n",
    "y_imputed = imputer.fit_transform(signdata[['SignBankEnglishTranslations']])\n",
    "\n",
    "# Convert the NumPy array back to a pandas Series\n",
    "y_imputed = pd.Series(y_imputed.flatten())\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_encoded = label_encoder.fit_transform(y_imputed)\n",
    "\n",
    "# Check for NaN values in the target variable after imputation\n",
    "nan_count_after_impute = pd.Series(y_imputed).isnull().sum()\n",
    "print(\"Number of NaN values in 'SignBankEnglishTranslations' column after imputation:\", nan_count_after_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importance = xgb_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top features\n",
    "selected_features = feature_importance_df.head(10)['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m rf_classifier \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the classifier on X_processed and y_encoded\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrf_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get feature importances\u001b[39;00m\n\u001b[1;32m     10\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m rf_classifier\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[0;32m--> 440\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[0;32m-> 2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2028\u001b[0m     )\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier on X_processed and y_encoded\n",
    "rf_classifier.fit(X_processed, y_encoded)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_processed.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select features with importance above threshold\n",
    "threshold = 0.03  # Adjust as needed\n",
    "selected_features_rf = feature_importance_df.loc[feature_importance_df['Importance'] > threshold, 'Feature'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
