{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from google.cloud import storage\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute SQL query to retrieve data\n",
    "cursor.execute(\"SELECT motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity, cluster_labels, gestureclass FROM UserData;\")\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Check if the fetched data is not empty\n",
    "if data:\n",
    "    # Extract individual columns from the fetched data\n",
    "    motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, cluster_labels, gestureclass = zip(*data)\n",
    "\n",
    "    # Ensure that the data are concatenated correctly for clustering\n",
    "    X = np.concatenate((motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, cluster_labels), axis=1)\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Set X and y for further processing\n",
    "    X = X_scaled\n",
    "    y = gestureclass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define your Keras model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(y.unique()), activation='softmax')  # Use softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile your model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical cross-entropy for integer labels\n",
    "              metrics=['accuracy'])  # Use accuracy as a metric\n",
    "\n",
    "# Train your model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate your model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('global_model_gesture_recognition.keras')\n",
    "\n",
    "# Initialize a client\n",
    "storage_client = storage.Client() #store model in Google cloud or any other cloud service?\n",
    "\n",
    "# Specify the bucket name and model file name\n",
    "bucket_name = 'your_bucket_name'  # Ensure it doesn't start with a '/'\n",
    "model_filename = 'global_model_gesture_recognition.keras'\n",
    "\n",
    "# Upload the model file to the bucket\n",
    "destination_blob_name = f'models/{model_filename}'  # Optional: Specify a folder path within the bucket\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
