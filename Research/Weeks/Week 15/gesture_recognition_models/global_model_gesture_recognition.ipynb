{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Execute SQL query to retrieve data\n",
    "cursor.execute(\"SELECT motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity, cluster_labels, gestureclass FROM UserData;\")\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Check if the fetched data is not empty\n",
    "if data:\n",
    "    # Extract individual columns from the fetched data\n",
    "    motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, cluster_labels, gestureclass = zip(*data)\n",
    "\n",
    "    # Ensure that the data are concatenated correctly for clustering\n",
    "    X = np.concatenate((motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, cluster_labels), axis=1)\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Set X and y for further processing\n",
    "    X = X_scaled\n",
    "    y = np.array(gestureclass)  # Convert to numpy array\n",
    "\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Define your Keras model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Use sigmoid activation for binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile your model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',  # Use binary cross-entropy for binary classification\n",
    "                  metrics=['accuracy'])  # Use accuracy as a metric\n",
    "\n",
    "    # Train your model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Evaluate your model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    predictions = model.predict_classes(X)\n",
    "\n",
    "    # Connect to the database again to update the predictions\n",
    "    conn = sqlite3.connect('your_database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Update the database with the predictions\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        cursor.execute(\"UPDATE UserData SET gestureclass = ? WHERE rowid = ?\", (prediction[0], i+1))\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "else:\n",
    "    pass  # Handle the case when there's no data fetched"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
