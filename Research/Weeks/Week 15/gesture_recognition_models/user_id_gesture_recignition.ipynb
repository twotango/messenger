{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from google.cloud import storage\n",
    "import uuid\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Replace the database URI with the appropriate URI for your global database management system\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///your_database.db'\n",
    "# Ensure the following configurations are set according to your database system\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "app.config['SECRET_KEY'] = 'your_secret_key_here'  # Secret key for Flask sessions\n",
    "\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "# User model\n",
    "class User(db.Model):\n",
    "    id = db.Column(db.String(36), primary_key=True, unique=True)\n",
    "    username = db.Column(db.String(80), unique=True, nullable=False)\n",
    "    email = db.Column(db.String(120), unique=True, nullable=False)\n",
    "    password = db.Column(db.String(80), nullable=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<User %r>' % self.username\n",
    "    \n",
    "# Function to load pre-trained model\n",
    "def load_pretrained_model():\n",
    "    # Specify the path to the pre-trained model file\n",
    "    pretrained_model_path = 'global_model_gesture_recognition.keras'\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    pretrained_model = load_model(pretrained_model_path)\n",
    "\n",
    "    return pretrained_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = load_pretrained_model()\n",
    "    \n",
    "def get_user_data_by_id(user_id):\n",
    "    # Query the database for user-specific data\n",
    "    motion_data = MotionData.query.filter_by(user_id=user_id).all()\n",
    "    image_data = ImageData.query.filter_by(user_id=user_id).all()\n",
    "    tap_data = Tap.query.filter_by(user_id=user_id).all()\n",
    "    phonetic_complexity_data = phonetic_complexity.query.filter_by(user_id=user_id).all()\n",
    "    phonetic_probability_data = phonetic_probability.query.filter_by(user_id=user_id).all()\n",
    "    iconizity_data = iconizity.query.filter_by(user_id=user_id).all()\n",
    "    gestureclass = gestureclass.query.filter_by(user_id=user_id).all()\n",
    "\n",
    "    # Process and convert data to NumPy arrays\n",
    "    motion_data = np.array([[entry.accelerometer_x, entry.accelerometer_y, entry.accelerometer_z, entry.attribute1, entry.attribute2, ...] for entry in motion_data])\n",
    "    image_data = np.array([[entry.handshape, entry.thumb_position, entry.minor_location, entry.major_location, entry.attribute1, entry.attribute2, ...] for entry in image_data])\n",
    "    tap_data = np.array([[entry.word, entry.sentence, entry.attribute1, entry.attribute2, ...] for entry in tap_data])\n",
    "    phonetic_complexity_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in phonetic_complexity_data])\n",
    "    phonetic_probability_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in phonetic_probability_data])\n",
    "    iconizity_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in iconizity_data])\n",
    "    gestureclass = np.array([[entry.attribute1, entry.attribute2, ...] for entry in gestureclass])\n",
    "\n",
    "    if not gestureclass.size:\n",
    "        pass\n",
    "\n",
    "    return motion_data, image_data, tap_data, phonetic_complexity_data, phonetic_probability_data, iconizity_data\n",
    "\n",
    "# Fine-tune the model based on user-specific data\n",
    "def fine_tune_model(model, user_data):\n",
    "    motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, gestureclass = user_data\n",
    "\n",
    "    # Combine motion, imagesign, and tap data\n",
    "    X = np.concatenate((motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data, gestureclass), axis=1)\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Predict cluster labels using the pretrained model\n",
    "    gestureclass = model.predict_classes(X_scaled)\n",
    "\n",
    "    # Define your Keras model for fine-tuning\n",
    "    # Example architecture, adjust as needed\n",
    "    fine_tuned_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(np.max(gestureclass) + 1, activation='softmax')  # Use softmax activation for multi-class classification\n",
    "    ])\n",
    "\n",
    "    # Compile your fine-tuned model\n",
    "    fine_tuned_model.compile(optimizer='adam',\n",
    "                              loss='sparse_categorical_crossentropy',  # Use sparse categorical cross-entropy for integer labels\n",
    "                              metrics=['accuracy'])  # Use accuracy as a metric\n",
    "\n",
    "    # Fine-tune your model\n",
    "    fine_tuned_model.fit(X_scaled, gestureclass, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    return fine_tuned_model\n",
    "\n",
    "# Function to save the fine-tuned model locally\n",
    "def save_model_locally(model, user_id):\n",
    "    filename = f'fine_tuned_model_gesture_recognition_{user_id}.keras'\n",
    "    model.save(filename)\n",
    "    return filename\n",
    "\n",
    "# Function to upload the fine-tuned model to Google Cloud Storage\n",
    "def upload_model_to_cloud(filename, bucket_name, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(filename)\n",
    "    print(f\"Model uploaded to cloud storage: gs://{bucket_name}/{destination_blob_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
