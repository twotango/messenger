{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from google.cloud import storage\n",
    "import uuid\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Replace the database URI with the appropriate URI for your global database management system\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///your_database.db'\n",
    "# Ensure the following configurations are set according to your database system\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "app.config['SECRET_KEY'] = 'your_secret_key_here'  # Secret key for Flask sessions\n",
    "\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "# User model\n",
    "class User(db.Model):\n",
    "    id = db.Column(db.String(36), primary_key=True, unique=True)\n",
    "    username = db.Column(db.String(80), unique=True, nullable=False)\n",
    "    email = db.Column(db.String(120), unique=True, nullable=False)\n",
    "    password = db.Column(db.String(80), nullable=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<User %r>' % self.username\n",
    "\n",
    "# Route for user registration\n",
    "@app.route('/register', methods=['GET', 'POST'])\n",
    "def register():\n",
    "    if request.method == 'POST':\n",
    "        username = request.form['username']\n",
    "        email = request.form['email']\n",
    "        password = request.form['password']\n",
    "\n",
    "        # Check if the email is already registered\n",
    "        if User.query.filter_by(email=email).first():\n",
    "            return render_template('register.html', message='Email already registered. Please use a different email.')\n",
    "\n",
    "        # Generate a unique user ID using UUID\n",
    "        user_id = str(uuid.uuid4())\n",
    "\n",
    "        # Create a new user record\n",
    "        new_user = User(id=user_id, username=username, email=email, password=password)\n",
    "        db.session.add(new_user)\n",
    "        db.session.commit()\n",
    "\n",
    "        return redirect(url_for('login'))  # Redirect to login page after registration\n",
    "    return render_template('register.html')\n",
    "\n",
    "# Route for user login\n",
    "@app.route('/login', methods=['GET', 'POST'])\n",
    "def login():\n",
    "    if request.method == 'POST':\n",
    "        email = request.form['email']\n",
    "        password = request.form['password']\n",
    "\n",
    "        # Check if the user exists and the password is correct\n",
    "        user = User.query.filter_by(email=email, password=password).first()\n",
    "        if user:\n",
    "            # Fetch user-specific data for the logged-in user\n",
    "            user_data = get_user_data_by_id(user.id)\n",
    "\n",
    "            # Load the pretrained model\n",
    "            pretrained_model = load_model('global_model.keras')\n",
    "\n",
    "            # Fine-tune the model based on user-specific data\n",
    "            fine_tuned_model = fine_tune_model(pretrained_model, user_data)\n",
    "\n",
    "            # Save the fine-tuned model locally\n",
    "            filename = save_model_locally(fine_tuned_model, user.id)\n",
    "\n",
    "            # Upload the fine-tuned model to Google Cloud Storage\n",
    "            upload_model_to_cloud(filename, 'your_bucket_name', f'fine_tuned_model_{user.id}.keras')\n",
    "\n",
    "            return redirect(url_for('dashboard'))  # Redirect to dashboard after login\n",
    "        else:\n",
    "            return render_template('login.html', message='Invalid email or password. Please try again.')\n",
    "    return render_template('login.html')\n",
    "\n",
    "def get_user_data_by_id(user_id):\n",
    "    # Query the database for user-specific data\n",
    "    motion_data = MotionData.query.filter_by(user_id=user_id).all()\n",
    "    image_data = ImageData.query.filter_by(user_id=user_id).all()\n",
    "    tap_data = Tap.query.filter_by(user_id=user_id).all()\n",
    "    phonetic_complexity_data = phonetic_complexity.query.filter_by(user_id=user_id).all()\n",
    "    phonetic_probability_data = phonetic_probability.query.filter_by(user_id=user_id).all()\n",
    "    iconizity_data = iconizity.query.filter_by(user_id=user_id).all()\n",
    "\n",
    "    # Process and convert data to NumPy arrays\n",
    "    motion_data = np.array([[entry.accelerometer_x, entry.accelerometer_y, entry.accelerometer_z, entry.attribute1, entry.attribute2, ...] for entry in motion_data])\n",
    "    image_data = np.array([[entry.handshape, entry.thumb_position, entry.minor_location, entry.major_location, entry.attribute1, entry.attribute2, ...] for entry in image_data])\n",
    "    tap_data = np.array([[entry.word, entry.sentence, entry.attribute1, entry.attribute2, ...] for entry in tap_data])\n",
    "    phonetic_complexity_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in phonetic_complexity_data])\n",
    "    phonetic_probability_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in phonetic_probability_data])\n",
    "    iconizity_data = np.array([[entry.attribute1, entry.attribute2, ...] for entry in iconizity_data])\n",
    "\n",
    "    # Perform one-hot encoding for tap data if available\n",
    "    if tap_data:\n",
    "        encoder = OneHotEncoder()\n",
    "        tap_encoded = encoder.fit_transform(tap_data).toarray()\n",
    "    else:\n",
    "        tap_encoded = None\n",
    "\n",
    "    # Check if any of the required data is missing\n",
    "    if not motion_data.size:\n",
    "        motion_data = None\n",
    "    if not image_data.size:\n",
    "        image_data = None\n",
    "    if not phonetic_complexity_data.size:\n",
    "        phonetic_complexity_data = None\n",
    "    if not phonetic_probability_data.size:\n",
    "        phonetic_probability_data = None\n",
    "    if not iconizity_data.size:\n",
    "        iconizity_data = None\n",
    "\n",
    "    return motion_data, image_data, tap_encoded, phonetic_complexity_data, phonetic_probability_data, iconizity_data\n",
    "\n",
    "# Fine-tune the model based on user-specific data\n",
    "def fine_tune_model(model, user_data):\n",
    "    motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data = user_data\n",
    "\n",
    "    # Combine motion, imagesign, and tap data\n",
    "    X = np.concatenate((motion, imagesign, tap, phonetic_complexity_data, phonetic_probability_data, iconizity_data), axis=1)\n",
    "\n",
    "    # Standardize the numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Predict cluster labels using the pretrained model\n",
    "    cluster_labels = model.predict_classes(X_scaled)\n",
    "\n",
    "    # Define your Keras model for fine-tuning\n",
    "    # Example architecture, adjust as needed\n",
    "    fine_tuned_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(np.max(cluster_labels) + 1, activation='softmax')  # Use softmax activation for multi-class classification\n",
    "    ])\n",
    "\n",
    "    # Compile your fine-tuned model\n",
    "    fine_tuned_model.compile(optimizer='adam',\n",
    "                              loss='sparse_categorical_crossentropy',  # Use sparse categorical cross-entropy for integer labels\n",
    "                              metrics=['accuracy'])  # Use accuracy as a metric\n",
    "\n",
    "    # Fine-tune your model\n",
    "    fine_tuned_model.fit(X_scaled, cluster_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    return fine_tuned_model\n",
    "\n",
    "# Function to save the fine-tuned model locally\n",
    "def save_model_locally(model, user_id):\n",
    "    filename = f'fine_tuned_model_cluster_{user_id}.keras'\n",
    "    model.save(filename)\n",
    "    return filename\n",
    "\n",
    "# Function to upload the fine-tuned model to Google Cloud Storage\n",
    "def upload_model_to_cloud(filename, bucket_name, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(filename)\n",
    "    print(f\"Model uploaded to cloud storage: gs://{bucket_name}/{destination_blob_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make that work, the \"def fetch_user_specific_data_for_current_user()\" has to be integrated in authentication mechanism. This example scripr covers registration, the triggered unique identifier, and also login case, plus fine-tining. Phonetic complexity, ph. probability, iconizity, tap, motion, and image sign data are checked for availability and set to \"None\" if not available, hence skipped in that case. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
