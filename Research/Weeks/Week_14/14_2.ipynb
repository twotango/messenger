{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/1207623996.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  smartphone = pd.read_csv('/Users/emilkoch/Desktop/2Tango/Data Files/Dataset_2_glasses/pivot_table_s_split.csv')\n"
     ]
    }
   ],
   "source": [
    "pivot_data4 = pd.read_csv('/Users/emilkoch/Desktop/2Tango/Data Files/Dataset_2_glasses/pivot_data4.csv')\n",
    "activity_type_full = pd.read_csv('/Users/emilkoch/Desktop/2Tango/Data Files/Dataset_2_glasses/report_full_activity_type.csv')\n",
    "smartphone = pd.read_csv('/Users/emilkoch/Desktop/2Tango/Data Files/Dataset_2_glasses/pivot_table_s_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_motion_row(row):\n",
    "    # Extract relevant data from the row\n",
    "    accel_x = row['accel_x']\n",
    "    accel_y = row['accel_y']\n",
    "    accel_z = row['accel_z']\n",
    "    gyro_x = row['gyro_x']\n",
    "    gyro_y = row['gyro_y']\n",
    "    gyro_z = row['gyro_z']\n",
    "\n",
    "    # Calculate magnitudes along x, y, and z axes\n",
    "    accel_mag_x_y = np.sqrt(accel_x**2 + accel_y**2)\n",
    "    accel_mag_z = np.abs(accel_z)\n",
    "    \n",
    "    # Classify motion based on accelerometer and gyroscope readings\n",
    "    if np.any((accel_x != 0) | (accel_y != 0) | (accel_z != 0)):\n",
    "        # Check if all gyroscope readings are zero\n",
    "        if not np.any((gyro_x != 0) | (gyro_y != 0) | (gyro_z != 0)):\n",
    "            # Check if there is significant upward or downward motion along the z-axis\n",
    "            if accel_z > 0 and accel_mag_x_y > accel_mag_z:\n",
    "                motion_type = \"Upward Horizontal Motion\"\n",
    "            elif accel_z < 0 and accel_mag_x_y > accel_mag_z:\n",
    "                motion_type = \"Downward Horizontal Motion\"\n",
    "            else:\n",
    "                motion_type = \"Other Moving\"\n",
    "        else:\n",
    "            # If gyroscope readings are not all zero, classify as \"Turning/Tilting\"\n",
    "            motion_type = \"Turning/Tilting\"\n",
    "    elif np.any((gyro_x != 0) | (gyro_y != 0) | (gyro_z != 0)):\n",
    "        # If accelerometer readings are all zero, check gyroscope readings\n",
    "        motion_type = \"Turning/Tilting\"\n",
    "    else:\n",
    "        # If both accelerometer and gyroscope readings are zero, classify as \"Stationary\"\n",
    "        motion_type = \"Stationary\"\n",
    "\n",
    "    return pd.Series([motion_type])\n",
    "\n",
    "# Apply the function row-wise to the dataframe\n",
    "pivot_data4['motion_type'] = pivot_data4.apply(classify_motion_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: 0, Decoding: Downward Horizontal Motion\n",
      "Encoding: 1, Decoding: Other Moving\n",
      "Encoding: 2, Decoding: Stationary\n",
      "Encoding: 3, Decoding: Turning/Tilting\n",
      "Encoding: 4, Decoding: Upward Horizontal Motion\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder_motion = LabelEncoder()\n",
    "pivot_data4['motion_encoded'] = label_encoder_motion.fit_transform(pivot_data4['motion_type'])\n",
    "\n",
    "# Save the LabelEncoder to a file\n",
    "joblib.dump(label_encoder_motion, '/Users/emilkoch/Desktop/2Tango/messenger/Research/Job_Library/label_encoder_motion.pkl')\n",
    "\n",
    "# Get the encodings and decodings\n",
    "encodings = label_encoder_motion.transform(label_encoder_motion.classes_)\n",
    "decodings = label_encoder_motion.classes_\n",
    "\n",
    "# Display the encodings and decodings\n",
    "for encoding, decoding in zip(encodings, decodings):\n",
    "    print(f\"Encoding: {encoding}, Decoding: {decoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data4.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 12:24:15.101925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3474/3474 [==============================] - 17s 4ms/step - loss: 1.3463 - accuracy: 0.8168 - val_loss: 0.5817 - val_accuracy: 0.9646\n",
      "Epoch 2/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.7781 - accuracy: 0.9363 - val_loss: 0.4851 - val_accuracy: 0.9655\n",
      "Epoch 3/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.6385 - accuracy: 0.9477 - val_loss: 0.4290 - val_accuracy: 0.9702\n",
      "Epoch 4/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5994 - accuracy: 0.9576 - val_loss: 0.4123 - val_accuracy: 0.9698\n",
      "Epoch 5/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5561 - accuracy: 0.9610 - val_loss: 0.4182 - val_accuracy: 0.9719\n",
      "Epoch 6/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5343 - accuracy: 0.9688 - val_loss: 0.3711 - val_accuracy: 0.9684\n",
      "Epoch 7/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5469 - accuracy: 0.9672 - val_loss: 0.3674 - val_accuracy: 0.9690\n",
      "Epoch 8/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5271 - accuracy: 0.9716 - val_loss: 0.3468 - val_accuracy: 0.9715\n",
      "Epoch 9/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5173 - accuracy: 0.9728 - val_loss: 0.4005 - val_accuracy: 0.9732\n",
      "Epoch 10/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.5040 - accuracy: 0.9739 - val_loss: 0.3529 - val_accuracy: 0.9683\n",
      "Epoch 11/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.4856 - accuracy: 0.9726 - val_loss: 0.3279 - val_accuracy: 0.9690\n",
      "Epoch 12/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.4820 - accuracy: 0.9739 - val_loss: 0.3469 - val_accuracy: 0.9707\n",
      "Epoch 13/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.4999 - accuracy: 0.9764 - val_loss: 0.3445 - val_accuracy: 0.9677\n",
      "Epoch 14/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.4984 - accuracy: 0.9761 - val_loss: 0.3105 - val_accuracy: 0.9693\n",
      "Epoch 15/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.4884 - accuracy: 0.9747 - val_loss: 0.3448 - val_accuracy: 0.9704\n",
      "Epoch 16/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.4745 - accuracy: 0.9773 - val_loss: 0.3337 - val_accuracy: 0.9702\n",
      "Epoch 17/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.4905 - accuracy: 0.9742 - val_loss: 0.3079 - val_accuracy: 0.9714\n",
      "Epoch 18/20\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.4900 - accuracy: 0.9758 - val_loss: 0.3482 - val_accuracy: 0.9714\n",
      "Epoch 19/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.4694 - accuracy: 0.9759 - val_loss: 0.3241 - val_accuracy: 0.9683\n",
      "Epoch 20/20\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.4791 - accuracy: 0.9749 - val_loss: 0.3127 - val_accuracy: 0.9693\n",
      "1086/1086 [==============================] - 2s 2ms/step - loss: 0.3135 - accuracy: 0.9705\n",
      "Test Accuracy: 0.9705467224121094\n",
      "1086/1086 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       655\n",
      "           1       0.82      0.92      0.87       398\n",
      "           2       0.97      1.00      0.99     31243\n",
      "           3       1.00      0.50      0.67      1775\n",
      "           4       0.97      0.88      0.92       662\n",
      "\n",
      "    accuracy                           0.97     34733\n",
      "   macro avg       0.94      0.85      0.88     34733\n",
      "weighted avg       0.97      0.97      0.97     34733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "y = pivot_data4['motion_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model with L1 regularization\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4['motion_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Encode class labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model with class weights and early stopping\n",
    "history = model.fit(X_train_scaled, y_train_encoded, epochs=20, validation_data=(X_val_scaled, y_val), class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/motion.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     timestamp  step_detector_values  audio_value_1  \\\n",
      "0      2017-06-29 07:45:16.506                   1.0            0.0   \n",
      "1      2017-06-29 07:45:17.407                   0.0            0.0   \n",
      "2      2017-06-29 07:45:18.407                   0.0          227.0   \n",
      "3      2017-06-29 07:45:19.407                   0.0          590.0   \n",
      "4      2017-06-29 07:45:20.446                   0.0         1724.0   \n",
      "...                        ...                   ...            ...   \n",
      "617948 2017-07-13 20:13:33.671                   0.0         1956.0   \n",
      "617949 2017-07-13 20:13:34.663                   0.0         2673.0   \n",
      "617950 2017-07-13 20:13:35.663                   0.0         2340.0   \n",
      "617951 2017-07-13 20:13:36.668                   0.0         2046.0   \n",
      "617952 2017-07-13 20:13:37.668                   0.0         2441.0   \n",
      "\n",
      "        audio_value_2  audio_value_3  audio_value_4 activity_type  \n",
      "0             0.00000            0.0            0.0   Video games  \n",
      "1             0.00000            0.0        32767.0   In computer  \n",
      "2           113.50000          227.0          227.0       At home  \n",
      "3           272.33334          590.0          227.0   In computer  \n",
      "4           635.25000         1724.0          227.0           Eat  \n",
      "...               ...            ...            ...           ...  \n",
      "617948     5246.24850        32767.0           30.0           NaN  \n",
      "617949     5246.18160        32767.0           30.0           NaN  \n",
      "617950     5246.10640        32767.0           30.0           NaN  \n",
      "617951     5246.02400        32767.0           30.0           NaN  \n",
      "617952     5245.95170        32767.0           30.0           NaN  \n",
      "\n",
      "[617953 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/4048118510.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_s_f['timestamp'] = pd.to_datetime(merged_data_s_f['timestamp'])\n",
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/4048118510.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_data_s_f['timestamp'] = merged_data_s_f['timestamp'].dt.hour * 60 + merged_data_s_f['timestamp'].dt.minute\n"
     ]
    }
   ],
   "source": [
    "smartphone = smartphone.drop(columns = ['activity_type'])\n",
    "# Convert timestamp columns to datetime objects\n",
    "activity_type_full['timestamp'] = pd.to_datetime(activity_type_full['timestamp'])\n",
    "smartphone['timestamp'] = pd.to_datetime(smartphone['timestamp'])\n",
    "# Convert timestamp columns to datetime objects\n",
    "activity_type_full['timestamp'] = pd.to_datetime(activity_type_full['timestamp'])\n",
    "smartphone['timestamp'] = pd.to_datetime(smartphone['timestamp'])\n",
    "\n",
    "# Group activity_type_full by timestamp and transform it to align with smartphone\n",
    "activity_type_grouped = activity_type_full.groupby(smartphone['timestamp'])['activity_type'].apply(lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "# Merge activity_type_grouped with smartphone based on timestamp\n",
    "smartphone = pd.merge(smartphone, activity_type_grouped, on='timestamp', how='left')\n",
    "\n",
    "# Print or further process the updated DataFrame\n",
    "print(smartphone)\n",
    "\n",
    "smartphone.fillna(0, inplace=True)\n",
    "\n",
    "# Filter the DataFrame to keep rows where \"activity_type\" is not equal to 0\n",
    "merged_data_s_f = smartphone[smartphone['activity_type'] != 0]\n",
    "# Assuming 'pivot_data4' is your DataFrame containing the timestamp column\n",
    "merged_data_s_f['timestamp'] = pd.to_datetime(merged_data_s_f['timestamp'])\n",
    "\n",
    "# Extract hour and minute from the timestamp and convert to minutes\n",
    "merged_data_s_f['timestamp'] = merged_data_s_f['timestamp'].dt.hour * 60 + merged_data_s_f['timestamp'].dt.minute\n",
    "\n",
    "merged_data_s_f_filtered = merged_data_s_f[['timestamp', 'activity_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'pivot_data4' is your DataFrame containing the timestamp column\n",
    "pivot_data4['timestamp'] = pd.to_datetime(pivot_data4['timestamp'])\n",
    "# Extract hour and minute from the timestamp and convert to minutes\n",
    "pivot_data4['timestamp'] = pivot_data4['timestamp'].dt.hour * 60 + pivot_data4['timestamp'].dt.minute\n",
    "# Merge the dataframes on the 'timestamp' column\n",
    "pivot_data4_merged = pivot_data4.merge(merged_data_s_f_filtered, on='timestamp', how='left')\n",
    "pivot_data4_merged.fillna(0, inplace=True)\n",
    "pivot_data4_merged_filtered = pivot_data4_merged[pivot_data4_merged['activity_type'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes:\n",
      "At home\n",
      "Cooking\n",
      "Eat\n",
      "Football\n",
      "In bus\n",
      "In computer\n",
      "In vehicle\n",
      "Meeting\n",
      "Movie\n",
      "On bus stop\n",
      "Pause\n",
      "Phone was out of the pocket (forgot)\n",
      "Picnic \n",
      "Running\n",
      "Shop\n",
      "Shopping& wearing\n",
      "Sleep\n",
      "Took off glasses\n",
      "Train\n",
      "Video games\n",
      "Walk\n",
      "Walking&party\n",
      "Watching TV\n",
      "Work\n",
      "Encoding: 0, Decoding: At home\n",
      "Encoding: 1, Decoding: Cooking\n",
      "Encoding: 2, Decoding: Eat\n",
      "Encoding: 3, Decoding: Football\n",
      "Encoding: 4, Decoding: In bus\n",
      "Encoding: 5, Decoding: In computer\n",
      "Encoding: 6, Decoding: In vehicle\n",
      "Encoding: 7, Decoding: Meeting\n",
      "Encoding: 8, Decoding: Movie\n",
      "Encoding: 9, Decoding: On bus stop\n",
      "Encoding: 10, Decoding: Pause\n",
      "Encoding: 11, Decoding: Phone was out of the pocket (forgot)\n",
      "Encoding: 12, Decoding: Picnic \n",
      "Encoding: 13, Decoding: Running\n",
      "Encoding: 14, Decoding: Shop\n",
      "Encoding: 15, Decoding: Shopping& wearing\n",
      "Encoding: 16, Decoding: Sleep\n",
      "Encoding: 17, Decoding: Took off glasses\n",
      "Encoding: 18, Decoding: Train\n",
      "Encoding: 19, Decoding: Video games\n",
      "Encoding: 20, Decoding: Walk\n",
      "Encoding: 21, Decoding: Walking&party\n",
      "Encoding: 22, Decoding: Watching TV\n",
      "Encoding: 23, Decoding: Work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/3103381586.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['activity_encoded'] = label_encoder_activities.fit_transform(pivot_data4_merged_filtered['activity_type'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create and fit the LabelEncoder\n",
    "label_encoder_activities = LabelEncoder()\n",
    "pivot_data4_merged_filtered['activity_encoded'] = label_encoder_activities.fit_transform(pivot_data4_merged_filtered['activity_type'])\n",
    "\n",
    "# Save the LabelEncoder to a file\n",
    "joblib.dump(label_encoder_activities, '/Users/emilkoch/Desktop/2Tango/messenger/Research/Job_Library/label_encoder_activities.pkl')\n",
    "\n",
    "# Get unique classes from the LabelEncoder\n",
    "unique_classes = label_encoder_activities.classes_\n",
    "\n",
    "# Print unique classes\n",
    "print(\"Unique Classes:\")\n",
    "for class_ in unique_classes:\n",
    "    print(class_)\n",
    "\n",
    "# Get the encodings and decodings\n",
    "encodings = label_encoder_activities.transform(label_encoder_activities.classes_)\n",
    "decodings = label_encoder_activities.classes_\n",
    "\n",
    "# Display the encodings and decodings\n",
    "for encoding, decoding in zip(encodings, decodings):\n",
    "    print(f\"Encoding: {encoding}, Decoding: {decoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_activity(row):\n",
    "    motion_type = row['motion_type']\n",
    "    if motion_type == \"Downward Horizontal Motion\":\n",
    "        return [13, 20, 21, 3, 6, 18, 4]\n",
    "    elif motion_type == \"Upward Horizontal Motion\":\n",
    "        return [6, 18, 4, 13, 20, 21, 3]\n",
    "    elif motion_type == \"Other Moving\":\n",
    "        return [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]\n",
    "    elif motion_type == \"Turning/Tilting\":\n",
    "        return [11, 17]\n",
    "    elif motion_type == \"Stationary\":\n",
    "        return [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]\n",
    "\n",
    "# Apply the function to create the predicted_activity column\n",
    "pivot_data4['predicted_activity'] = pivot_data4.apply(classify_activity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the classification function\n",
    "def classify_activity(row):\n",
    "    motion_type = row['motion_type']\n",
    "    activities = {\n",
    "        \"Downward Horizontal Motion\": [13, 20, 21, 3, 6, 18, 4],\n",
    "        \"Upward Horizontal Motion\": [6, 18, 4, 13, 20, 21, 3],\n",
    "        \"Other Moving\": [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3],\n",
    "        \"Turning/Tilting\": [11, 17],\n",
    "        \"Stationary\": [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]\n",
    "    }\n",
    "    activity_labels = []\n",
    "    for label in range(24):  # Assuming there are 24 possible activity labels\n",
    "        if any(label in activities[motion_type] for motion_type in activities):\n",
    "            activity_labels.append(1)\n",
    "        else:\n",
    "            activity_labels.append(0)\n",
    "    return activity_labels\n",
    "\n",
    "# Apply the function to create the predicted activity column\n",
    "pivot_data4['predicted_activity'] = pivot_data4.apply(classify_activity, axis=1)\n",
    "\n",
    "# Convert predicted_activity to binary vectors\n",
    "activity_df = pd.DataFrame(pivot_data4['predicted_activity'].tolist(), columns=[f'activity_{i}' for i in range(24)])\n",
    "X = pd.concat([pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']], activity_df], axis=1)\n",
    "y = pivot_data4['motion_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4['motion_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/motion.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>step_counter</th>\n",
       "      <th>step_detector</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>linear_accel_x</th>\n",
       "      <th>...</th>\n",
       "      <th>rotation_scalar</th>\n",
       "      <th>rotation_i</th>\n",
       "      <th>rotation_j</th>\n",
       "      <th>rotation_k</th>\n",
       "      <th>rotation_angle</th>\n",
       "      <th>motion_type</th>\n",
       "      <th>motion_encoded</th>\n",
       "      <th>predicted_activity</th>\n",
       "      <th>true_motion</th>\n",
       "      <th>activity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.344086</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>9.967361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Other Moving</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Turning/Tilting</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173657</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173658</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173659</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173660</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173661</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173662 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  step_counter  step_detector   accel_x   accel_y   accel_z  \\\n",
       "0             465           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "1             466           0.0            0.0 -0.344086  0.683304  9.967361   \n",
       "2             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "3             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "4             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "...           ...           ...            ...       ...       ...       ...   \n",
       "173657       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173658       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173659       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173660       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173661       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "          gyro_x    gyro_y    gyro_z  linear_accel_x  ...  rotation_scalar  \\\n",
       "0       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "1       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "2       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "3       0.000000  0.000000  0.000000       -0.018069  ...              0.0   \n",
       "4       0.004166 -0.013275  0.006165        0.000000  ...              0.0   \n",
       "...          ...       ...       ...             ...  ...              ...   \n",
       "173657  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173658  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173659  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173660  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173661  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "\n",
       "        rotation_i  rotation_j  rotation_k  rotation_angle      motion_type  \\\n",
       "0              0.0         0.0         0.0             0.0       Stationary   \n",
       "1              0.0         0.0         0.0             0.0     Other Moving   \n",
       "2              0.0         0.0         0.0             0.0       Stationary   \n",
       "3              0.0         0.0         0.0             0.0       Stationary   \n",
       "4              0.0         0.0         0.0             0.0  Turning/Tilting   \n",
       "...            ...         ...         ...             ...              ...   \n",
       "173657         0.0         0.0         0.0             0.0       Stationary   \n",
       "173658         0.0         0.0         0.0             0.0       Stationary   \n",
       "173659         0.0         0.0         0.0             0.0       Stationary   \n",
       "173660         0.0         0.0         0.0             0.0       Stationary   \n",
       "173661         0.0         0.0         0.0             0.0       Stationary   \n",
       "\n",
       "        motion_encoded                                 predicted_activity  \\\n",
       "0                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1                    1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4                    3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                ...                                                ...   \n",
       "173657               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173658               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173659               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173660               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173661               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "        true_motion  activity_encoded  \n",
       "0                 1                 3  \n",
       "1                 1                15  \n",
       "2                 1                 8  \n",
       "3                 1                 8  \n",
       "4                 1                 8  \n",
       "...             ...               ...  \n",
       "173657            3                17  \n",
       "173658            3                17  \n",
       "173659            3                17  \n",
       "173660            3                17  \n",
       "173661            3                17  \n",
       "\n",
       "[173662 rows x 25 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/179481233.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def classify_motion_activity(row):\n",
    "    activity_encoded = row['activity_encoded']\n",
    "    if activity_encoded in [13, 20, 21, 3, 6, 18, 4]:\n",
    "        true_motion = 0\n",
    "    elif activity_encoded in [6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 4\n",
    "    elif activity_encoded in [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 1\n",
    "    elif activity_encoded in [11, 17]:\n",
    "        true_motion = 3\n",
    "    elif activity_encoded in [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]:\n",
    "        true_motion = 2\n",
    "    return true_motion\n",
    "\n",
    "# Assuming 'pivot_data4' is your DataFrame\n",
    "pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/202448761.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pivot_data4_merged_filtered.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in X\n",
    "nan_values = pivot_data4_merged_filtered.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/963641440.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 4s 5ms/step - loss: 2.7410 - accuracy: 0.1967 - val_loss: 2.0258 - val_accuracy: 0.3021\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0659 - accuracy: 0.2805 - val_loss: 1.7399 - val_accuracy: 0.3647\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.8653 - accuracy: 0.3034 - val_loss: 1.6429 - val_accuracy: 0.3444\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7665 - accuracy: 0.3123 - val_loss: 1.5979 - val_accuracy: 0.3662\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.7070 - accuracy: 0.3272 - val_loss: 1.5726 - val_accuracy: 0.3657\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6688 - accuracy: 0.3274 - val_loss: 1.5495 - val_accuracy: 0.3433\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6406 - accuracy: 0.3268 - val_loss: 1.5319 - val_accuracy: 0.3688\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.6282 - accuracy: 0.3322 - val_loss: 1.5212 - val_accuracy: 0.3652\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6116 - accuracy: 0.3344 - val_loss: 1.5144 - val_accuracy: 0.3657\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.5974 - accuracy: 0.3351 - val_loss: 1.5085 - val_accuracy: 0.3637\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6041 - accuracy: 0.3344 - val_loss: 1.5006 - val_accuracy: 0.3530\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5809 - accuracy: 0.3313 - val_loss: 1.4938 - val_accuracy: 0.3739\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.5814 - accuracy: 0.3392 - val_loss: 1.4898 - val_accuracy: 0.3510\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 1.5732 - accuracy: 0.3393 - val_loss: 1.4888 - val_accuracy: 0.3795\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5674 - accuracy: 0.3445 - val_loss: 1.4808 - val_accuracy: 0.3795\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.5594 - accuracy: 0.3421 - val_loss: 1.4775 - val_accuracy: 0.3779\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 1s 6ms/step - loss: 1.5617 - accuracy: 0.3396 - val_loss: 1.4741 - val_accuracy: 0.3840\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5510 - accuracy: 0.3476 - val_loss: 1.4762 - val_accuracy: 0.3759\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5502 - accuracy: 0.3411 - val_loss: 1.4802 - val_accuracy: 0.3774\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.5500 - accuracy: 0.3429 - val_loss: 1.4718 - val_accuracy: 0.3800\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.4862 - accuracy: 0.3602\n",
      "Test Accuracy: 0.3601953685283661\n",
      "77/77 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       141\n",
      "           1       0.00      0.00      0.00        73\n",
      "           2       0.28      1.00      0.44       243\n",
      "           3       0.00      0.00      0.00        37\n",
      "           4       0.42      0.80      0.55       458\n",
      "           5       0.00      0.00      0.00       173\n",
      "           6       0.00      0.00      0.00       135\n",
      "           7       0.34      0.97      0.50       116\n",
      "           8       0.40      0.02      0.03       119\n",
      "           9       0.00      0.00      0.00        14\n",
      "          10       0.00      0.00      0.00       112\n",
      "          13       0.00      0.00      0.00        16\n",
      "          14       0.00      0.00      0.00        71\n",
      "          15       0.00      0.00      0.00        32\n",
      "          17       1.00      1.00      1.00        23\n",
      "          18       0.00      0.00      0.00       115\n",
      "          19       0.00      0.00      0.00        78\n",
      "          20       0.39      0.32      0.35       438\n",
      "          21       0.00      0.00      0.00        33\n",
      "          23       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.36      2457\n",
      "   macro avg       0.14      0.20      0.14      2457\n",
      "weighted avg       0.22      0.36      0.24      2457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the classification function for motion activity\n",
    "def classify_motion_activity(row):\n",
    "    activity_encoded = row['activity_encoded']\n",
    "    if activity_encoded in [13, 20, 21, 3, 6, 18, 4]:\n",
    "        true_motion = 0\n",
    "    elif activity_encoded in [6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 4\n",
    "    elif activity_encoded in [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 1\n",
    "    elif activity_encoded in [11, 17]:\n",
    "        true_motion = 3\n",
    "    elif activity_encoded in [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]:\n",
    "        true_motion = 2\n",
    "    return true_motion\n",
    "\n",
    "# Apply the function to create the 'true_motion' column\n",
    "pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp']]\n",
    "y = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4_merged_filtered['activity_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/activities.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline seems to function well. Much better than previously when using the same model for predicting the multiple possible activity classes and single-true classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reading, CNN model architecture seems to be used often for sensor readings. Let's test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/939017988.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 4s 5ms/step - loss: 3.8787 - accuracy: 0.0709 - val_loss: 2.9474 - val_accuracy: 0.0504\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 3.0744 - accuracy: 0.1118 - val_loss: 2.6874 - val_accuracy: 0.0839\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.9214 - accuracy: 0.1196 - val_loss: 2.5109 - val_accuracy: 0.1226\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.5372 - accuracy: 0.1183 - val_loss: 2.4462 - val_accuracy: 0.1089\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.7070 - accuracy: 0.1223 - val_loss: 2.3393 - val_accuracy: 0.1099\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.7376 - accuracy: 0.1256 - val_loss: 2.3005 - val_accuracy: 0.1134\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.3783 - accuracy: 0.1201 - val_loss: 2.2742 - val_accuracy: 0.1175\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.5031 - accuracy: 0.1230 - val_loss: 2.2148 - val_accuracy: 0.1170\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0984 - accuracy: 0.1216 - val_loss: 2.1603 - val_accuracy: 0.1083\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0950 - accuracy: 0.1174 - val_loss: 2.1094 - val_accuracy: 0.1089\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.1024 - accuracy: 0.1153 - val_loss: 2.1140 - val_accuracy: 0.1165\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.2044 - accuracy: 0.1190 - val_loss: 2.0555 - val_accuracy: 0.1170\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.1605 - accuracy: 0.1254 - val_loss: 2.0222 - val_accuracy: 0.1099\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0419 - accuracy: 0.1162 - val_loss: 2.0169 - val_accuracy: 0.1063\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.9923 - accuracy: 0.1206 - val_loss: 1.9930 - val_accuracy: 0.2375\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0236 - accuracy: 0.1384 - val_loss: 1.9918 - val_accuracy: 0.1083\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9311 - accuracy: 0.1196 - val_loss: 1.9970 - val_accuracy: 0.0895\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9586 - accuracy: 0.1148 - val_loss: 1.9667 - val_accuracy: 0.0885\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.8996 - accuracy: 0.1289 - val_loss: 1.9820 - val_accuracy: 0.0895\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9510 - accuracy: 0.1104 - val_loss: 1.9468 - val_accuracy: 0.0946\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.9166 - accuracy: 0.1038\n",
      "Test Accuracy: 0.10378510504961014\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.01      0.01       141\n",
      "           1       0.32      0.16      0.22        73\n",
      "           2       0.00      0.00      0.00       243\n",
      "           3       0.04      0.95      0.08        37\n",
      "           4       0.28      0.01      0.02       458\n",
      "           5       0.00      0.00      0.00       173\n",
      "           6       0.15      0.02      0.04       135\n",
      "           7       0.50      0.01      0.02       116\n",
      "           8       0.33      0.03      0.05       119\n",
      "           9       0.04      0.07      0.05        14\n",
      "          10       0.18      0.82      0.29       112\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.05      0.94      0.09        16\n",
      "          14       0.00      0.00      0.00        71\n",
      "          15       0.11      0.97      0.20        32\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.72      1.00      0.84        23\n",
      "          18       0.00      0.00      0.00       115\n",
      "          19       0.00      0.00      0.00        78\n",
      "          20       0.50      0.01      0.02       438\n",
      "          21       0.07      0.06      0.06        33\n",
      "          23       0.10      0.90      0.18        30\n",
      "\n",
      "    accuracy                           0.10      2457\n",
      "   macro avg       0.16      0.27      0.10      2457\n",
      "weighted avg       0.23      0.10      0.05      2457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the classification function for motion activity\n",
    "def classify_motion_activity(row):\n",
    "    activity_encoded = row['activity_encoded']\n",
    "    if activity_encoded in [13, 20, 21, 3, 6, 18, 4]:\n",
    "        true_motion = 0\n",
    "    elif activity_encoded in [6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 4\n",
    "    elif activity_encoded in [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 1\n",
    "    elif activity_encoded in [11, 17]:\n",
    "        true_motion = 3\n",
    "    elif activity_encoded in [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]:\n",
    "        true_motion = 2\n",
    "    return true_motion\n",
    "\n",
    "# Apply the function to create the 'true_motion' column\n",
    "pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp']]\n",
    "y = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4_merged_filtered['activity_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Encode class labels for the new target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/3157097494.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 3s 5ms/step - loss: 3.0462 - accuracy: 0.1047 - val_loss: 2.5486 - val_accuracy: 0.0641\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.7464 - accuracy: 0.1439 - val_loss: 2.2695 - val_accuracy: 0.1419\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.5809 - accuracy: 0.1388 - val_loss: 2.1659 - val_accuracy: 0.1267\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 6ms/step - loss: 2.3109 - accuracy: 0.1408 - val_loss: 2.0643 - val_accuracy: 0.1399\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.2527 - accuracy: 0.1344 - val_loss: 1.9805 - val_accuracy: 0.1083\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.1700 - accuracy: 0.1341 - val_loss: 2.0296 - val_accuracy: 0.0855\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0945 - accuracy: 0.1361 - val_loss: 1.9926 - val_accuracy: 0.0824\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9145 - accuracy: 0.1251 - val_loss: 1.9258 - val_accuracy: 0.1211\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.8495 - accuracy: 0.1421 - val_loss: 1.8709 - val_accuracy: 0.0951\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9386 - accuracy: 0.1187 - val_loss: 2.0276 - val_accuracy: 0.0585\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.9130 - accuracy: 0.1126 - val_loss: 1.9248 - val_accuracy: 0.0972\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.7345 - accuracy: 0.1308 - val_loss: 1.8546 - val_accuracy: 0.1256\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7029 - accuracy: 0.1469 - val_loss: 1.8680 - val_accuracy: 0.0910\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7179 - accuracy: 0.1300 - val_loss: 1.8254 - val_accuracy: 0.0966\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5344 - accuracy: 0.1324 - val_loss: 1.8240 - val_accuracy: 0.1287\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.5536 - accuracy: 0.1354 - val_loss: 1.8169 - val_accuracy: 0.1063\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5088 - accuracy: 0.1398 - val_loss: 1.8021 - val_accuracy: 0.1175\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.7648 - accuracy: 0.1303 - val_loss: 1.8064 - val_accuracy: 0.1322\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5704 - accuracy: 0.1350 - val_loss: 1.7944 - val_accuracy: 0.1165\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5665 - accuracy: 0.1266 - val_loss: 1.8341 - val_accuracy: 0.1063\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 1.8262 - accuracy: 0.1164\n",
      "Test Accuracy: 0.11640211939811707\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       141\n",
      "           1       0.41      0.18      0.25        73\n",
      "           2       0.00      0.00      0.00       243\n",
      "           3       0.04      1.00      0.08        37\n",
      "           4       0.00      0.00      0.00       458\n",
      "           5       0.18      0.02      0.04       173\n",
      "           6       0.00      0.00      0.00       135\n",
      "           7       0.00      0.00      0.00       116\n",
      "           8       0.38      0.89      0.54       119\n",
      "           9       0.05      0.93      0.09        14\n",
      "          10       0.00      0.00      0.00       112\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.04      0.75      0.07        16\n",
      "          14       0.00      0.00      0.00        71\n",
      "          15       0.03      0.03      0.03        32\n",
      "          17       1.00      1.00      1.00        23\n",
      "          18       0.00      0.00      0.00       115\n",
      "          19       0.14      0.95      0.24        78\n",
      "          20       0.00      0.00      0.00       438\n",
      "          21       0.11      0.06      0.08        33\n",
      "          23       0.07      0.03      0.05        30\n",
      "\n",
      "    accuracy                           0.12      2457\n",
      "   macro avg       0.12      0.28      0.12      2457\n",
      "weighted avg       0.06      0.12      0.06      2457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the classification function for motion activity\n",
    "def classify_motion_activity(row):\n",
    "    activity_encoded = row['activity_encoded']\n",
    "    if activity_encoded in [13, 20, 21, 3, 6, 18, 4]:\n",
    "        true_motion = 0\n",
    "    elif activity_encoded in [6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 4\n",
    "    elif activity_encoded in [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 1\n",
    "    elif activity_encoded in [11, 17]:\n",
    "        true_motion = 3\n",
    "    elif activity_encoded in [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]:\n",
    "        true_motion = 2\n",
    "    return true_motion\n",
    "\n",
    "# Apply the function to create the 'true_motion' column\n",
    "pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp']]\n",
    "y = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the data for compatibility with CNN\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(pivot_data4_merged_filtered['activity_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Encode class labels for the new target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=20, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/activities.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/5qs7726s3_dc54vtgh1sc2740000gn/T/ipykernel_2413/2334679296.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 5s 7ms/step - loss: 3.1379 - accuracy: 0.1412 - val_loss: 3.0016 - val_accuracy: 0.2091\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.7848 - accuracy: 0.1668 - val_loss: 2.6059 - val_accuracy: 0.2325\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.4108 - accuracy: 0.1440 - val_loss: 2.2718 - val_accuracy: 0.1017\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.3666 - accuracy: 0.1434 - val_loss: 2.2146 - val_accuracy: 0.1109\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.2710 - accuracy: 0.1363 - val_loss: 2.1147 - val_accuracy: 0.1144\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 2.1692 - accuracy: 0.1433 - val_loss: 2.1057 - val_accuracy: 0.0860\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 6ms/step - loss: 1.9625 - accuracy: 0.1305 - val_loss: 2.0343 - val_accuracy: 0.1165\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 2.0040 - accuracy: 0.1345 - val_loss: 1.9914 - val_accuracy: 0.1211\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.8809 - accuracy: 0.1314 - val_loss: 1.9870 - val_accuracy: 0.0992\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.9363 - accuracy: 0.1350 - val_loss: 1.9890 - val_accuracy: 0.1231\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.9377 - accuracy: 0.1249 - val_loss: 1.9999 - val_accuracy: 0.0936\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.8443 - accuracy: 0.1282 - val_loss: 1.9870 - val_accuracy: 0.0921\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7280 - accuracy: 0.1279 - val_loss: 1.9627 - val_accuracy: 0.1119\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7112 - accuracy: 0.1328 - val_loss: 1.9402 - val_accuracy: 0.0936\n",
      "Epoch 15/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6503 - accuracy: 0.1280 - val_loss: 1.9230 - val_accuracy: 0.0936\n",
      "Epoch 16/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.6417 - accuracy: 0.1248 - val_loss: 1.9293 - val_accuracy: 0.0870\n",
      "Epoch 17/20\n",
      "246/246 [==============================] - 1s 6ms/step - loss: 1.7700 - accuracy: 0.1238 - val_loss: 1.8912 - val_accuracy: 0.0926\n",
      "Epoch 18/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.5671 - accuracy: 0.1247 - val_loss: 1.9188 - val_accuracy: 0.1190\n",
      "Epoch 19/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.8904 - accuracy: 0.1261 - val_loss: 1.8997 - val_accuracy: 0.1038\n",
      "Epoch 20/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.7565 - accuracy: 0.1160 - val_loss: 1.8912 - val_accuracy: 0.0997\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.8698 - accuracy: 0.0997\n",
      "Test Accuracy: 0.09971509873867035\n",
      "77/77 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.02      0.04       141\n",
      "           1       0.42      0.18      0.25        73\n",
      "           2       0.00      0.00      0.00       243\n",
      "           3       0.04      0.92      0.08        37\n",
      "           4       0.33      0.03      0.06       458\n",
      "           5       0.00      0.00      0.00       173\n",
      "           6       0.20      0.06      0.09       135\n",
      "           7       0.50      0.01      0.02       116\n",
      "           8       0.00      0.00      0.00       119\n",
      "           9       0.00      0.00      0.00        14\n",
      "          10       0.00      0.00      0.00       112\n",
      "          13       0.04      0.69      0.07        16\n",
      "          14       0.20      0.01      0.03        71\n",
      "          15       0.11      1.00      0.19        32\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.85      1.00      0.92        23\n",
      "          18       0.20      0.01      0.02       115\n",
      "          19       0.14      0.94      0.24        78\n",
      "          20       0.00      0.00      0.00       438\n",
      "          21       0.06      0.09      0.07        33\n",
      "          23       0.10      0.93      0.18        30\n",
      "\n",
      "    accuracy                           0.10      2457\n",
      "   macro avg       0.16      0.28      0.11      2457\n",
      "weighted avg       0.15      0.10      0.05      2457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the classification function for motion activity\n",
    "def classify_motion_activity(row):\n",
    "    activity_encoded = row['activity_encoded']\n",
    "    if activity_encoded in [13, 20, 21, 3, 6, 18, 4]:\n",
    "        true_motion = 0\n",
    "    elif activity_encoded in [6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 4\n",
    "    elif activity_encoded in [1, 7, 8, 15, 6, 18, 4, 13, 20, 21, 3]:\n",
    "        true_motion = 1\n",
    "    elif activity_encoded in [11, 17]:\n",
    "        true_motion = 3\n",
    "    elif activity_encoded in [0, 10, 14, 23, 2, 16, 22, 12, 19, 5, 9]:\n",
    "        true_motion = 2\n",
    "    return true_motion\n",
    "\n",
    "# Apply the function to create the 'true_motion' column\n",
    "pivot_data4_merged_filtered['true_motion'] = pivot_data4_merged_filtered.apply(classify_motion_activity, axis=1)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp']]\n",
    "y = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape data for LSTM (samples, timesteps, features)\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    LSTM(units=64, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4_merged_filtered['activity_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Encode class labels for the new target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=20, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_reshaped)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN model architecture has the best performance out of the neural networks without class_weights = balanced. But CNN has best performance with class weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'motion_encoded', 'timestamp']]\n",
    "y = pivot_data4['predicted_activity']\n",
    "\n",
    "# Convert labels into binary format for multi-label classification\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Initialize a multi-output classifier with GradientBoostingClassifier as the base estimator\n",
    "multi_gb_model = MultiOutputClassifier(GradientBoostingClassifier())\n",
    "\n",
    "# Train the model\n",
    "multi_gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy_gb = multi_gb_model.score(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy (Gradient Boosting):\", test_accuracy_gb)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = multi_gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_gb, target_names=mlb.classes_.astype(str)))\n",
    "\n",
    "# Define the file path to save the model\n",
    "model_file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/Research/Model_Save/multi_gb_model.pkl\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(multi_gb_model, model_file_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load the previously trained model\n",
    "model = load_model(\"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/activities.keras\")\n",
    "\n",
    "# Define the new target variable (y) using single true labels\n",
    "y_single_true_labels = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Convert labels into binary format for single-label classification\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_single_true_binary = label_binarizer.fit_transform(y_single_true_labels)\n",
    "\n",
    "# Filter X to include only rows with true labels\n",
    "X_filtered = X.loc[y_single_true_labels.index]\n",
    "\n",
    "# Split the filtered data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_single_true_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Retrain the model with class weights\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.2, verbose=1, callbacks=[EarlyStopping(patience=5)])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/activities.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_binarizer.classes_.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"/Users/emilkoch/Desktop/2Tango/messenger/Research/Model_Save/multi_gb_model.pkl\")\n",
    "\n",
    "# Define the new target variable (y) using single true labels\n",
    "y_single_true_labels = pivot_data4_merged_filtered['activity_encoded']\n",
    "\n",
    "# Convert labels into binary format for single-label classification\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_single_true_binary = label_binarizer.fit_transform(y_single_true_labels)\n",
    "\n",
    "# Filter X to include only rows with true labels\n",
    "X_filtered = X.loc[y_single_true_labels.index]\n",
    "\n",
    "# Split the filtered data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_single_true_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "multi_gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy_gb = multi_gb_model.score(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy (Gradient Boosting):\", test_accuracy_gb)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = multi_gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_gb, target_names=mlb.classes_.astype(str)))\n",
    "\n",
    "# Define the file path to save the model\n",
    "model_file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/Research/Model_Save/multi_gb_model.pkl\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(multi_gb_model, model_file_path)\n",
    "\n",
    "print(\"Model saved successfully at:\", model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/motion.keras\")\n",
    "\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "\n",
    "# Define the new target variable (y) using single true labels\n",
    "y = pivot_data4_merged_filtered['true_motion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encode class labels for the new target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model with class weights and early stopping\n",
    "history = loaded_model.fit(X_train_scaled, y_train_encoded, epochs=100, batch_size= 45, validation_data=(X_val_scaled, y_val), class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the retrained model on the test set\n",
    "test_loss, test_accuracy = loaded_model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = loaded_model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Stationary\n",
       "1            Other Moving\n",
       "2              Stationary\n",
       "3              Stationary\n",
       "4         Turning/Tilting\n",
       "               ...       \n",
       "173657         Stationary\n",
       "173658         Stationary\n",
       "173659         Stationary\n",
       "173660         Stationary\n",
       "173661         Stationary\n",
       "Name: motion_encoded, Length: 173662, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_data4['motion_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "246/246 [==============================] - 3s 5ms/step - loss: 2.7252 - accuracy: 0.1330 - val_loss: 1.8795 - val_accuracy: 0.1353\n",
      "Epoch 2/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.7463 - accuracy: 0.2331 - val_loss: 1.3540 - val_accuracy: 0.1450\n",
      "Epoch 3/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.4851 - accuracy: 0.2358 - val_loss: 1.3102 - val_accuracy: 0.1414\n",
      "Epoch 4/20\n",
      "246/246 [==============================] - 1s 6ms/step - loss: 1.3126 - accuracy: 0.2135 - val_loss: 1.3098 - val_accuracy: 0.1287\n",
      "Epoch 5/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.2559 - accuracy: 0.1977 - val_loss: 1.2800 - val_accuracy: 0.1328\n",
      "Epoch 6/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.2493 - accuracy: 0.1990 - val_loss: 1.3164 - val_accuracy: 0.1343\n",
      "Epoch 7/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.2378 - accuracy: 0.1744 - val_loss: 1.3327 - val_accuracy: 0.1211\n",
      "Epoch 8/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.2096 - accuracy: 0.1800 - val_loss: 1.2927 - val_accuracy: 0.1205\n",
      "Epoch 9/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.1563 - accuracy: 0.1602 - val_loss: 1.2068 - val_accuracy: 0.1450\n",
      "Epoch 10/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.1795 - accuracy: 0.1808 - val_loss: 1.3187 - val_accuracy: 0.1200\n",
      "Epoch 11/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.1916 - accuracy: 0.1430 - val_loss: 1.2564 - val_accuracy: 0.1287\n",
      "Epoch 12/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.1731 - accuracy: 0.1559 - val_loss: 1.2760 - val_accuracy: 0.1241\n",
      "Epoch 13/20\n",
      "246/246 [==============================] - 1s 4ms/step - loss: 1.1797 - accuracy: 0.1382 - val_loss: 1.2667 - val_accuracy: 0.1231\n",
      "Epoch 14/20\n",
      "246/246 [==============================] - 1s 5ms/step - loss: 1.1714 - accuracy: 0.1606 - val_loss: 1.2418 - val_accuracy: 0.1333\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.2335 - accuracy: 0.1579\n",
      "Test Accuracy: 0.15791615843772888\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.05      0.09      1232\n",
      "           1       0.18      0.88      0.29       340\n",
      "           2       0.39      0.01      0.02       862\n",
      "           3       0.03      0.83      0.06        23\n",
      "\n",
      "    accuracy                           0.16      2457\n",
      "   macro avg       0.28      0.44      0.12      2457\n",
      "weighted avg       0.43      0.16      0.09      2457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4_merged_filtered[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'timestamp']]\n",
    "y = pivot_data4_merged_filtered['true_motion']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(np.unique(pivot_data4_merged_filtered['activity_encoded'])), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Encode class labels for the new target variable\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Compute class weights using the encoded labels\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_encoded), y=y_train_encoded)\n",
    "\n",
    "# Create a class weight dictionary\n",
    "class_weight_dict = dict(zip(le.transform(le.classes_), class_weights))\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_split=0.2, class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/true_motion.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5427/5427 [==============================] - 11s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"/Users/emilkoch/Desktop/2Tango/messenger/Research/Model_Save/true_motion.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Preprocess the unlabeled data\n",
    "X_unlabeled_scaled = scaler.transform(pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'timestamp']])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Assuming your model outputs probabilities and you want to select the class with the highest probability\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Add the predicted labels to the DataFrame\n",
    "pivot_data4['true_motion'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5427/5427 [==============================] - 11s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/activities.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Preprocess the unlabeled data\n",
    "X_unlabeled_scaled = scaler.transform(pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp']])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Assuming your model outputs probabilities and you want to select the class with the highest probability\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Add the predicted labels to the DataFrame\n",
    "pivot_data4['activity_encoded'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>step_counter</th>\n",
       "      <th>step_detector</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>linear_accel_x</th>\n",
       "      <th>...</th>\n",
       "      <th>rotation_scalar</th>\n",
       "      <th>rotation_i</th>\n",
       "      <th>rotation_j</th>\n",
       "      <th>rotation_k</th>\n",
       "      <th>rotation_angle</th>\n",
       "      <th>motion_type</th>\n",
       "      <th>motion_encoded</th>\n",
       "      <th>predicted_activity</th>\n",
       "      <th>true_motion</th>\n",
       "      <th>activity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.344086</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>9.967361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Other Moving</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Turning/Tilting</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173657</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173658</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173659</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173660</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173661</th>\n",
       "      <td>1221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173662 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  step_counter  step_detector   accel_x   accel_y   accel_z  \\\n",
       "0             465           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "1             466           0.0            0.0 -0.344086  0.683304  9.967361   \n",
       "2             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "3             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "4             466           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "...           ...           ...            ...       ...       ...       ...   \n",
       "173657       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173658       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173659       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173660       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "173661       1221           0.0            0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "          gyro_x    gyro_y    gyro_z  linear_accel_x  ...  rotation_scalar  \\\n",
       "0       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "1       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "2       0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "3       0.000000  0.000000  0.000000       -0.018069  ...              0.0   \n",
       "4       0.004166 -0.013275  0.006165        0.000000  ...              0.0   \n",
       "...          ...       ...       ...             ...  ...              ...   \n",
       "173657  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173658  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173659  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173660  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "173661  0.000000  0.000000  0.000000        0.000000  ...              0.0   \n",
       "\n",
       "        rotation_i  rotation_j  rotation_k  rotation_angle      motion_type  \\\n",
       "0              0.0         0.0         0.0             0.0       Stationary   \n",
       "1              0.0         0.0         0.0             0.0     Other Moving   \n",
       "2              0.0         0.0         0.0             0.0       Stationary   \n",
       "3              0.0         0.0         0.0             0.0       Stationary   \n",
       "4              0.0         0.0         0.0             0.0  Turning/Tilting   \n",
       "...            ...         ...         ...             ...              ...   \n",
       "173657         0.0         0.0         0.0             0.0       Stationary   \n",
       "173658         0.0         0.0         0.0             0.0       Stationary   \n",
       "173659         0.0         0.0         0.0             0.0       Stationary   \n",
       "173660         0.0         0.0         0.0             0.0       Stationary   \n",
       "173661         0.0         0.0         0.0             0.0       Stationary   \n",
       "\n",
       "        motion_encoded                                 predicted_activity  \\\n",
       "0                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1                    1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3                    2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4                    3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                ...                                                ...   \n",
       "173657               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173658               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173659               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173660               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "173661               2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "        true_motion  activity_encoded  \n",
       "0                 1                 3  \n",
       "1                 1                15  \n",
       "2                 1                 8  \n",
       "3                 1                 8  \n",
       "4                 1                 8  \n",
       "...             ...               ...  \n",
       "173657            3                17  \n",
       "173658            3                17  \n",
       "173659            3                17  \n",
       "173660            3                17  \n",
       "173661            3                17  \n",
       "\n",
       "[173662 rows x 25 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3474/3474 [==============================] - 16s 4ms/step - loss: 0.1127 - accuracy: 0.0949 - val_loss: 0.0784 - val_accuracy: 0.0188\n",
      "Epoch 2/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0499 - accuracy: 0.0824 - val_loss: 0.0651 - val_accuracy: 0.0075\n",
      "Epoch 3/10\n",
      "3474/3474 [==============================] - 15s 4ms/step - loss: 0.0405 - accuracy: 0.0810 - val_loss: 0.0646 - val_accuracy: 0.0032\n",
      "Epoch 4/10\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.0381 - accuracy: 0.0973 - val_loss: 0.0609 - val_accuracy: 0.0081\n",
      "Epoch 5/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0354 - accuracy: 0.0977 - val_loss: 0.0553 - val_accuracy: 0.0071\n",
      "Epoch 6/10\n",
      "3474/3474 [==============================] - 13s 4ms/step - loss: 0.0326 - accuracy: 0.0866 - val_loss: 0.0630 - val_accuracy: 0.0127\n",
      "Epoch 7/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0302 - accuracy: 0.0811 - val_loss: 0.0637 - val_accuracy: 0.0195\n",
      "Epoch 8/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0295 - accuracy: 0.0714 - val_loss: 0.0607 - val_accuracy: 0.0131\n",
      "Epoch 9/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0282 - accuracy: 0.0739 - val_loss: 0.0671 - val_accuracy: 0.0246\n",
      "Epoch 10/10\n",
      "3474/3474 [==============================] - 14s 4ms/step - loss: 0.0272 - accuracy: 0.0599 - val_loss: 0.0684 - val_accuracy: 0.0259\n",
      "1086/1086 [==============================] - 2s 2ms/step - loss: 0.0681 - accuracy: 0.0274\n",
      "Test Loss: 0.06812959909439087\n",
      "Test Accuracy: 0.027437882497906685\n",
      "1086/1086 [==============================] - 3s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     31243\n",
      "           1       0.79      0.81      0.80       398\n",
      "           2       0.97      1.00      0.98     31243\n",
      "           3       1.00      1.00      1.00      1715\n",
      "           4       1.00      1.00      1.00      1715\n",
      "           5       0.97      1.00      0.98     31243\n",
      "           6       1.00      1.00      1.00      1715\n",
      "           7       0.79      0.81      0.80       398\n",
      "           8       0.79      0.81      0.80       398\n",
      "           9       0.97      1.00      0.98     31243\n",
      "          10       0.97      1.00      0.98     31243\n",
      "          11       1.00      0.44      0.61      1775\n",
      "          12       0.97      1.00      0.98     31243\n",
      "          13       1.00      1.00      1.00      1715\n",
      "          14       0.97      1.00      0.98     31243\n",
      "          15       0.79      0.81      0.80       398\n",
      "          16       0.97      1.00      0.98     31243\n",
      "          17       1.00      0.44      0.61      1775\n",
      "          18       1.00      1.00      1.00      1715\n",
      "          19       0.97      1.00      0.98     31243\n",
      "          20       1.00      1.00      1.00      1715\n",
      "          21       1.00      1.00      1.00      1715\n",
      "          22       0.97      1.00      0.98     31243\n",
      "          23       0.97      1.00      0.98     31243\n",
      "\n",
      "   micro avg       0.97      0.99      0.98    360820\n",
      "   macro avg       0.95      0.92      0.93    360820\n",
      "weighted avg       0.97      0.99      0.98    360820\n",
      " samples avg       0.97      0.97      0.97    360820\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = pivot_data4[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'true_motion', 'timestamp', 'activity_encoded']]\n",
    "y = pivot_data4['predicted_activity']\n",
    "\n",
    "# Convert labels into binary format for multi-label classification\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(len(mlb.classes_), activation='sigmoid')  # Sigmoid activation for multi-label classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1, callbacks=[EarlyStopping(patience=5)])\n",
    "\n",
    "# Save the model\n",
    "file_path = \"/Users/emilkoch/Desktop/2Tango/messenger/research/Model_Save/predicted_activities.keras\"\n",
    "save_model(model, file_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Convert predictions back to original labels\n",
    "y_pred_labels = mlb.inverse_transform(y_pred)\n",
    "\n",
    "# Convert ground truth labels back to original format\n",
    "y_true_labels = mlb.inverse_transform(y_test)\n",
    "\n",
    "# Convert ground truth labels to binary array format\n",
    "y_true_binary = mlb.transform(y_true_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_binary, y_pred, target_names=mlb.classes_.astype(str)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
